<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: open source | Brandon Hilkert]]></title>
  <link href="http://brandonhilkert.com/blog/categories/open-source/atom.xml" rel="self"/>
  <link href="http://brandonhilkert.com/"/>
  <updated>2017-04-24T10:17:39-04:00</updated>
  <id>http://brandonhilkert.com/</id>
  <author>
    <name><![CDATA[Brandon Hilkert]]></name>
    <email><![CDATA[brandonhilkert@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Rails Progress Indicator for Turbolinks Using Nprogress]]></title>
    <link href="http://brandonhilkert.com/blog/rails-progress-indicator-for-turbolinks-using-nprogress/"/>
    <updated>2016-04-29T09:44:00-04:00</updated>
    <id>http://brandonhilkert.com/blog/rails-progress-indicator-for-turbolinks-using-nprogress</id>
    <content type="html"><![CDATA[<p>Contrary to popular opinion, I&rsquo;m a fan of <a href="https://github.com/turbolinks/turbolinks">Turbolinks</a>.
I leave it enabled in all my Rails applications. Most of the negative opinions I hear relate to it &ldquo;breaking&rdquo; third-party jQuery plugins. I say &ldquo;breaking&rdquo; because it&rsquo;s not <em>really</em> changing the plugin&rsquo;s behavior &mdash; just requires the plugin to be initialized differently.</p>

<!--more-->


<p>If you&rsquo;re upgrading to a newer version of Rails and have a bunch of legacy JavaScript code, I can imagine this being difficult. But if you&rsquo;re green-fielding a new application, there&rsquo;s no reason not to take advantage of it. I wrote extensively about <a href="http://brandonhilkert.com/blog/organizing-javascript-in-rails-application-with-turbolinks/">how to organize JavaScript in a Rails application with Turbolinks enabled</a>. If you&rsquo;re struggling to get your JavaScript code to work as expected on clicks through the application, take a look at that post. I continue to use that organization pattern for all my applications and it never lets me down.</p>

<p>With Turbolinks enabled, interacting with an application feels smooth and fast. No more full page refreshes.</p>

<p>Every once in awhile we&rsquo;ll stumble on a page request takes longer than others. Rather than having the user sit there thinking nothing is happening, we can offer better feedback through a loading progress bar, specifically <a href="http://ricostacruz.com/nprogress/">nprogress</a>. I&rsquo;ve found it to be the perfect companion to Turbolinks to create a great user experience.</p>

<h2>The Problem</h2>

<p>In a traditional web application, when we click a link or submit a form, we get a loading spinner where the favicon typically appears. We might also see text in the status bar saying &ldquo;Connecting&hellip;&rdquo; or &ldquo;Loading&hellip;&rdquo;. These are the loading indications that internet users have become accustomed to.</p>

<p>By adopting Turbolinks, we not longer get those loading feedback mechanisms because the request for the new page is asynchronous. Once the request is complete, the new content is rendered in place of the previous page&rsquo;s body element. For fast page loads, this isn&rsquo;t a problem. However, if you have applications like mine, every once in awhile, you might have a page request take a few seconds (reasons for this are beyond the scope of this article). In those cases, a user might click a link and sit there for 2-3 sec. without any indication the page is loading. While Turbolinks generally improves the user experience of our application, having no user feedback for several seconds is not ideal (ideally, you&rsquo;d want to address a page request that takes multiple seconds). This is where <code>nprogress</code> can help.</p>

<h2>The Solution</h2>

<p><a href="http://ricostacruz.com/nprogress/"><code>nprogress</code></a> is a progress loading indicator, like what you see on YouTube.</p>

<p>Like other JavaScript libraries, there&rsquo;s <a href="https://github.com/caarlos0/nprogress-rails">a Ruby Gem that vendors the code and includes it in the Rails asset pipeline</a>.</p>

<p>We&rsquo;ll first add <code>nprogress-rails</code> to our Gemfile:</p>

<p><code>
gem "nprogress-rails"
</code></p>

<p>Bundle to install the new gem:</p>

<p><code>
$ bundle install
</code></p>

<p>Now with <code>nprogress</code> installed, we need to include the JavaScript in our application. We&rsquo;ll do this by adding the following the <code>app/assets/javascripts/application.js</code> manifest:</p>

<p><code>
//= require nprogress
//= require nprogress-turbolinks
</code></p>

<p>We first include the <code>nprogress</code> JavaScript source, and then an adapter that&rsquo;ll hook the Turbolinks request to the progress indicator.</p>

<p><em>Note: If you&rsquo;re familiar with Turbolinks and its events, you&rsquo;ll recognize the <a href="https://github.com/caarlos0/nprogress-rails/blob/master/app/assets/javascripts/nprogress-turbolinks.js">events triggered</a>.</em></p>

<p>By default, the <code>nprogress</code> loading bar is anchored to the top of the browser window, but we need to include some CSS to make this work. Let&rsquo;s open the <code>app/assets/stylesheets/application.scss</code> manifest file and add the following:</p>

<p><code>
*= require nprogress
*= require nprogress-bootstrap
</code></p>

<p><em>Note: Including <code>nprogress-bootstrap</code> isn&rsquo;t necessary if you don&rsquo;t use <a href="http://getbootstrap.com/css/">Bootstrap</a> in your application. I typically do, so I&rsquo;m going to include it.</em></p>

<p>At this point, we&rsquo;ll have a working loading indicator. But what if we want to tweak the styles to match your application&rsquo;s theme?</p>

<h2>Customizing Nprogress Styles</h2>

<p>Because the <a href="https://github.com/caarlos0/nprogress-rails/blob/master/app/assets/stylesheets/nprogress.scss#L1"><code>nprgress</code> styles are Sass</a>, we can overwrite the variables for customization.</p>

<p>There are 3 variables available to overwite:</p>

<ul>
<li><code>$nprogress-color</code></li>
<li><code>$nprogress-height</code></li>
<li><code>$nprogress-zindex</code></li>
</ul>


<p>For <a href="https://www.bark.us/">Bark</a>, we have an aqua accent color with use throughout the site. It made sense for the <code>nprogress</code> loading indicator to be that same color.</p>

<p>Back in our <code>app/assets/stylesheets/application.scss</code>, I overwrote the variable before including the <code>nprogress</code> source code:</p>

<p>```
$nprogress-color: #37c8c9;</p>

<p>@import &ldquo;nprogress&rdquo;;
@import &ldquo;nprogress-bootstrap&rdquo;;
```</p>

<h2>Summary</h2>

<p>I&rsquo;ve found <code>nprogress</code> to be a great companion library to Turbolinks. The two libraries together provide a much better user experience over full page refreshes. Turbolinks helps asynchronously load the page content that&rsquo;s changing and <code>nprogress</code> gives the user feedback that their request is in progress. Now, even when a user has to suffer through multi-second page loads, at least they&rsquo;ll know it&rsquo;s not broken and don&rsquo;t have to click again.</p>

<p>The <a href="https://github.com/turbolinks/turbolinks/blob/master/src/turbolinks/progress_bar.coffee">latest version of Turbolinks has a progress bar
built-in</a>.
I&rsquo;m looking forward to removing the dependency if it performs similarly.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Guide to Ruby Gem Post-Install Messages]]></title>
    <link href="http://brandonhilkert.com/blog/ruby-gem-post-install-message/"/>
    <updated>2016-04-22T20:13:00-04:00</updated>
    <id>http://brandonhilkert.com/blog/ruby-gem-post-install-message</id>
    <content type="html"><![CDATA[<p>As gem authors, one of the ways we can provide important information to users of our gems is through post-install messages. Let&rsquo;s explore what they are, how to set them up, what to include and when to use them.</p>

<!--more-->


<h2>What are Post-Install Messages?</h2>

<p>As Rubyists, we have plenty experiences installing gems. By running <code>gem install rails</code>, we&rsquo;re asking Rubygems to install the gem named <code>rails</code> on to our system.</p>

<p>The typical output of installing a gem with no other dependencies (assuming it completes successfully) is minimal:</p>

<p><figure class="code"><pre><code class="bash">$ gem install so_meta
Successfully installed so_meta-0.1
1 gem installed
</code></pre></figure></p>

<p>As you can see, we ran <code>gem install so_meta</code> and the output confirmed the install, with nothing more.</p>

<p>If you&rsquo;ve used the <a href="https://github.com/jnunemaker/httparty">HTTParty</a> gem, you&rsquo;ve probably seen the additional line of output it generates when you run <code>gem install httparty</code>:</p>

<p><figure class="code"><pre><code class="bash">$ gem install httparty
When you HTTParty, you must party hard!
Successfully installed httparty-0.13.7
1 gem installed
</code></pre></figure></p>

<p>Where did <code>When you HTTParty, you must party hard!</code> come from? It turns out the source of that text was a [post-install message defined in the <a href="https://github.com/jnunemaker/httparty/blob/v0.13.7/httparty.gemspec#L22"><code>gemspec</code></a>.</p>

<p>Now, I know what you&rsquo;re probably thinking&hellip;what good is that message? That&rsquo;s up for debate. In fact, that specific message in <code>HTTParty</code> has been the source of much debate over the years.</p>

<h2>How to configure a Post-Install Message</h2>

<p>As we&rsquo;ve seen before, the <code>gemspec</code> file (located at the root of the gem) defines the specification of a Ruby gem. Using bundler to bootstrap a new gem will automatically create this file. Here&rsquo;s an example of a default <code>gemspec</code> file created by bundler using the command <code>bundle gem brandon</code> (<code>brandon</code> being the name of my fake gem):</p>

<p><figure class="code"><pre><code class="ruby"># coding: utf-8
lib = File.expand_path(&lsquo;../lib&rsquo;, <strong>FILE</strong>)
$LOAD_PATH.unshift(lib) unless $LOAD_PATH.include?(lib)
require &lsquo;brandon/version&rsquo;</p>

<p>Gem::Specification.new do |spec|
  spec.name          = &ldquo;brandon&rdquo;
  spec.version       = Brandon::VERSION
  spec.authors       = [&ldquo;Brandon Hilkert&rdquo;]
  spec.email         = [&ldquo;<a href="&#x6d;&#97;&#105;&#108;&#x74;&#111;&#58;&#x62;&#114;&#x61;&#x6e;&#x64;&#111;&#x6e;&#x68;&#x69;&#108;&#107;&#101;&#x72;&#x74;&#x40;&#x67;&#x6d;&#97;&#x69;&#108;&#x2e;&#x63;&#x6f;&#x6d;">&#98;&#x72;&#x61;&#110;&#100;&#x6f;&#110;&#104;&#x69;&#x6c;&#x6b;&#101;&#114;&#116;&#64;&#x67;&#109;&#97;&#x69;&#x6c;&#x2e;&#x63;&#x6f;&#109;</a>&rdquo;]</p>

<p>  spec.summary       = %q{TODO: Write a short summary, because Rubygems requires one.}
  spec.description   = %q{TODO: Write a longer description or delete this line.}
  spec.homepage      = &ldquo;TODO: Put your gem&rsquo;s website or public repo URL here.&rdquo;</p>

<p>  # Prevent pushing this gem to RubyGems.org by setting &lsquo;allowed_push_host&rsquo;, or
  # delete this section to allow pushing this gem to any host.
  if spec.respond_to?(:metadata)</p>

<pre><code>spec.metadata['allowed_push_host'] = "TODO: Set to 'http://mygemserver.com'"
</code></pre>

<p>  else</p>

<pre><code>raise "RubyGems 2.0 or newer is required to protect against public gem pushes."
</code></pre>

<p>  end</p>

<p>  spec.files         = <code>git ls-files -z</code>.split(&ldquo;\x0&rdquo;).reject { |f| f.match(%r{^(test|spec|features)/}) }
  spec.bindir        = &ldquo;exe&rdquo;
  spec.executables   = spec.files.grep(%r{^exe/}) { |f| File.basename(f) }
  spec.require_paths = [&ldquo;lib&rdquo;]</p>

<p>  spec.add_development_dependency &ldquo;bundler&rdquo;, &ldquo;~> 1.11&rdquo;
  spec.add_development_dependency &ldquo;rake&rdquo;, &ldquo;~> 10.0&rdquo;
  spec.add_development_dependency &ldquo;minitest&rdquo;, &ldquo;~> 5.0&rdquo;
end
</code></pre></figure></p>

<p>Aside from <code>summary</code>, <code>description</code>, and <code>homepage</code>, we can leave the rest of this file intact. These setter attributes on the <code>Gem::Specification.new</code> instance allow us to define the options and metadata necessary to properly configure and release a Ruby gem (see <a href="http://guides.rubygems.org/specification-reference/">the Rubygems specification reference</a> for an extensive list of options).</p>

<p>As you might have guessed by now, a post-install message is an <a href="http://guides.rubygems.org/specification-reference/#post_install_message">option available in the gemspec</a>. The value can be a simple string or a more complex <a href="https://en.wikipedia.org/wiki/Here_document">heredoc</a>.</p>

<p>The simplest example being:</p>

<p><figure class="code"><pre><code class="ruby">spec.post_install_message = &ldquo;My test post-install message.&rdquo;
</code></pre></figure></p>

<p>With that in our <code>gemspec</code>, now when we install our fake gem <code>brandon</code>, we&rsquo;ll see the following output:</p>

<p><figure class="code"><pre><code class="bash">$ gem install brandon
My test post-install message.
Successfully installed brandon-0.1.0
1 gem installed
</code></pre></figure></p>

<p>Easy, huh?</p>

<p>If we wanted to include a more complex message with line breaks and other formatting, another option would be something like:</p>

<p><figure class="code"><pre><code class="ruby">s.post_install_message = %q{
My test post-install message.</p>

<p>Another post-install message a few lines down.
}
</code></pre></figure></p>

<p>The formatting of these messages can get weird because whitespace is preserved in multiline strings. If you&rsquo;re looking to include anything more complex than a simple string literal, it&rsquo;s worth experimenting by installing locally and confirming it&rsquo;s what you want.</p>

<p>The <a href="https://github.com/newrelic/rpm">NewRelic gem</a> is another example that comes to mind that commonly includes more than just a simple string. Looking back at an <a href="https://github.com/newrelic/rpm/blob/v2.12.0/newrelic_rpm.gemspec#L193">older version of the NewRelic gem</a> yields the following <code>post_install_message</code>:</p>

<p><figure class="code"><pre><code class="ruby">s.post_install_message = %q{
Please see <a href="http://support.newrelic.com/faqs/docs/ruby-agent-release-notes">http://support.newrelic.com/faqs/docs/ruby-agent-release-notes</a>
for a complete description of the features and enhancements available
in version 2.12 of the Ruby Agent.</p>

<p>For details on this specific release, refer to the CHANGELOG file.</p>

<p>}
</code></pre></figure></p>

<p>Notice the message includes a line break both before and after the message. This will help isolate from our post-install messages when included in the longer output of a command like <code>bundle install</code>. Again, if you&rsquo;re focused on formatting and getting it right, it&rsquo;s worth installing locally in to something like a Rails application which yields more output than using <code>gem install [gemname]</code>.</p>

<h2>When to Use Post-Install Messages</h2>

<p>The examples above use post-install messages for different reasons. <code>HTTParty</code>&rsquo;s message wasn&rsquo;t for a serious technical or information reason, just a light-hearted message that&rsquo;s garnered quite a bit of negative attention from users that don&rsquo;t appreciate it.</p>

<p>My suggestion would be to avoid any non-sensical messages and only provide a post-install message for something like breaking changes or information you think is critical to the usage of your gem. In most cases, <strong>post-install messages are most useful when a user is upgrading from an older version of your gem and the new version includes backwards-incompatible changes</strong>. Whether is be syntactical changes or core functionality, post-install messages provide us as gem authors a means to keep our users updated.</p>

<h2>What to Include in Post-Install Messages</h2>

<p>If you&rsquo;re adhering to semantic versioning and introduce any breaking changes in a major release, a post-install message is a great way to warn users about the changes. However, one thing you want to avoid is enumerating your gem&rsquo;s full changelog in the message. In most cases, a short notice about the backwards incompatible changes and a URL for more information is enough.</p>

<p>I <a href="http://brandonhilkert.com/blog/lessons-learned-from-building-a-ruby-gem-api/">introduced a new public API in Sucker Punch</a>, which warranted a major release. Because of these backwards-incompatible changes, I added a post-install message to the new version:</p>

<p><figure class="code"><pre><code class="bash">$ gem install sucker_punch
Fetching: sucker_punch-2.0.1.gem (100%)
Sucker Punch v2.0 introduces backwards-incompatible changes.
Please see <a href="https://github.com/brandonhilkert/sucker_punch/blob/master/CHANGES.md#20">https://github.com/brandonhilkert/sucker_punch/blob/master/CHANGES.md#20</a> for details.
Successfully installed sucker_punch-2.0.1
1 gem installed
</code></pre></figure></p>

<p>&ldquo;Sucker Punch v2.0 introduces backwards-incompatible changes&rdquo; provided the heads up that something was different. The URL in the following line allows the users to see a more extension list of the changes and to make adjustments in their application if necessary.</p>

<h2>Summary</h2>

<p>In addition to documentation through a <code>README</code> or wiki, post-install messages are a great way to keep users of our gems informed. Having access to the output of their console is a privilege, so use it sparingly. Like the boy who cried wolf, if we include a wall of text with each release of our gem, users will learn to ignore it and that would negatively affect its value for everyone.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Solving backwards compatibility in Ruby with a proxy object]]></title>
    <link href="http://brandonhilkert.com/blog/solving-backwards-compatibility-in-ruby-with-a-proxy-object/"/>
    <updated>2016-01-26T07:00:00-05:00</updated>
    <id>http://brandonhilkert.com/blog/solving-backwards-compatibility-in-ruby-with-a-proxy-object</id>
    <content type="html"><![CDATA[<p>In a previous article, I <a href="http://brandonhilkert.com/blog/lessons-learned-from-building-a-ruby-gem-api/">documented the upcoming public API changes slated for Sucker Punch v2</a>. Because of a poor initial design, these API changes are <strong>backwards incompatible</strong>.</p>

<p>When I published the previous article, <a href="https://twitter.com/mperham/status/684529380446441472">Mike Perham rightly pointed out the opportunity to support the previous versions&rsquo;s API through an opt-in module</a>. I was hesitant to include support for the old syntax by default, but allowing a developer to require a file to get the old syntax made complete sense to me. My intent was never to abandon existing Sucker Punch users, but it felt necessary for the success of the project going forward.</p>

<!--more-->


<h2>The Problem</h2>

<p>The following is an example of enqueueing a background job with Sucker Punch using the old syntax:</p>

<p><code>
LogJob.new.async.perform("new_user")
</code></p>

<p>And with the new syntax:</p>

<p><code>
LogJob.perform_async("new_user")
</code></p>

<p><em>How do we support the old syntax in the new version?</em></p>

<p>Let&rsquo;s step back and reminder ourselves of what a typical job class looks like:</p>

<p>```
class LogJob
  include SuckerPunch::Job</p>

<p>  def perform(event)</p>

<pre><code>Log.new(event).track
</code></pre>

<p>  end
end
```</p>

<p>Important points to notice:</p>

<ol>
<li>Each job includes the <code>SuckerPunch::Job</code> module to gain access to asynchronous behavior</li>
<li>Each job executes its logic using the <code>perform</code> instance method</li>
<li>Each job passes arguments needed for its logic as arguments to the <code>perform</code> instance method</li>
</ol>


<h2>The Solution</h2>

<p>We&rsquo;ll start with the test:</p>

<p>```</p>

<h1>test/sucker_punch/async_syntax_test.rb</h1>

<p>require &lsquo;test_helper&rsquo;</p>

<p>module SuckerPunch
  class AsyncSyntaxTest &lt; Minitest::Test</p>

<pre><code>def setup
  require 'sucker_punch/async_syntax'
end

def test_perform_async_runs_job_asynchronously
  arr = []
  latch = Concurrent::CountDownLatch.new
  FakeLatchJob.new.async.perform(arr, latch)
  latch.wait(0.2)
  assert_equal 1, arr.size
end

private

class FakeLatchJob
  include SuckerPunch::Job

  def perform(arr, latch)
    arr.push true
    latch.count_down
  end
end
</code></pre>

<p>  end
end
```</p>

<p><em>Note: Some details of this are complex because the job&rsquo;s code is running in another thread. I&rsquo;ll walk through those details in a future article.</em></p>

<p>The basic sequence is:
1. require <code>sucker_punch/async_syntax</code>
2. Execute a background job using the <code>async</code> syntax
3. Assert changes made in that job were successful</p>

<p>Running the tests above, we get the following error:</p>

<p><code>``
1) Error:
SuckerPunch::AsyncSyntaxTest#test_perform_async_runs_job_asynchronously:
LoadError: cannot load such file -- sucker_punch/async_syntax
  /Users/bhilkert/Dropbox/code/sucker_punch/test/sucker_punch/async_syntax_test.rb:6:in</code>require'
  /Users/bhilkert/Dropbox/code/sucker_punch/test/sucker_punch/async_syntax_test.rb:6:in `setup'</p>

<p>1 runs, 0 assertions, 0 failures, 1 errors, 0 skips
```</p>

<p>Ok, so the file doesn&rsquo;t exist. Let&rsquo;s create it and re-run the tests:</p>

<p><code>
1) Error:
SuckerPunch::AsyncSyntaxTest#test_perform_async_runs_job_asynchronously:
NoMethodError: undefined method `async' for #&lt;SuckerPunch::AsyncSyntaxTest::FakeLatchJob:0x007fbc73cbf548&gt;
  /Users/bhilkert/Dropbox/code/sucker_punch/test/sucker_punch/async_syntax_test.rb:12:in `test_perform_async_runs_job_asynchronously'
</code></p>

<p>Progress! The job doesn&rsquo;t have an <code>async</code> method. Let&rsquo;s add it:</p>

<p>```
module SuckerPunch
  module Job</p>

<pre><code>def async # &lt;--- New method
end
</code></pre>

<p>  end
end
```</p>

<p><em>Notice: We&rsquo;re monkey-patching the <code>SuckerPunch::Job</code> module. This will allow us to add methods to the background job since it&rsquo;s included in the job.</em></p>

<p>The tests now:</p>

<p><code>
1) Error:
SuckerPunch::AsyncSyntaxTest#test_perform_async_runs_job_asynchronously:
NoMethodError: undefined method `perform' for nil:NilClass
  /Users/bhilkert/Dropbox/code/sucker_punch/test/sucker_punch/async_syntax_test.rb:12:in `test_perform_async_runs_job_asynchronously'
</code></p>

<p>More progress&hellip;the <code>async</code> method we added returns nil, and because of the syntax <code>async.perform</code>, there&rsquo;s no <code>perform</code> method on the output of <code>async</code>. In short, we need to return something from <code>async</code> that responds to <code>perform</code> and can run the job.</p>

<p>In its most basic form, suppose we create a proxy object that responds to <code>perform</code>:</p>

<p><code>
class AsyncProxy
  def perform
  end
end
</code></p>

<p>We&rsquo;ll need to do some work in <code>perform</code> to execute the job, but this&rsquo;ll do for now. Now, let&rsquo;s integrate this new proxy to our <code>async_syntax.rb</code> file and return a new instance of the proxy from the <code>async</code> method:</p>

<p>```
module SuckerPunch
  module Job</p>

<pre><code>def async
  AsyncProxy.new # &lt;--- new instance of the proxy
end
</code></pre>

<p>  end</p>

<p>  class AsyncProxy</p>

<pre><code>def perform
end
</code></pre>

<p>  end
end
```</p>

<p>Running our tests gives us the following:</p>

<p><code>
1) Error:
SuckerPunch::AsyncSyntaxTest#test_perform_async_runs_job_asynchronously:
ArgumentError: wrong number of arguments (2 for 0)
  /Users/bhilkert/Dropbox/code/sucker_punch/lib/sucker_punch/async_syntax.rb:9:in `perform'
  /Users/bhilkert/Dropbox/code/sucker_punch/test/sucker_punch/async_syntax_test.rb:12:in `test_perform_async_runs_job_asynchronously'
</code></p>

<p>Now we&rsquo;re on to something. We see an error related to the number of arguments on the <code>perform</code> method. Because each job&rsquo;s argument list will be different, we need to find a way to be flexible for whatever&rsquo;s passed in, something like&hellip;the splat operator! Let&rsquo;s try it:</p>

<p>```
module SuckerPunch
  module Job</p>

<pre><code>def async
  AsyncProxy.new
end
</code></pre>

<p>  end</p>

<p>  class AsyncProxy</p>

<pre><code>def perform(*args) # &lt;--- Adding the splat operator, will handle any # of args
end
</code></pre>

<p>  end
end
```</p>

<p>The tests now:</p>

<p><code>
1) Failure:
SuckerPunch::AsyncSyntaxTest#test_perform_async_runs_job_asynchronously [/Users/bhilkert/Dropbox/code/sucker_punch/test/sucker_punch/async_syntax_test.rb:14]:
Expected: 1
Actual: 0
</code></p>

<p>At this point, we&rsquo;ve reached the end of test output suggesting the path forward. This error is saying, &ldquo;Your assertions failed.&rdquo;. This is good because it means our syntax implementation will work and it&rsquo;s just about executing the actual job code in the proxy&rsquo;s <code>perform</code> method.</p>

<p>We want to leverage our new syntax (<code>perform_async</code>) to run the actual job asynchronously so it passes through the standard code path. To do so, we&rsquo;ll need a reference to the original job in the proxy object. Let&rsquo;s pass that to the proxy during instantiation:</p>

<p>```
module SuckerPunch
  module Job</p>

<pre><code>def async
  AsyncProxy.new(self) # &lt;--- Pass the job instance
end
</code></pre>

<p>  end</p>

<p>  class AsyncProxy</p>

<pre><code>def initialize(job) # &lt;--- Handle job passed in
  @job = job
end

def perform(*args)
end
</code></pre>

<p>  end
end
```</p>

<p>Now that the proxy has a reference to the job instance, we can call the <code>perform_async</code> class method to execute the job:</p>

<p>```
module SuckerPunch
  module Job</p>

<pre><code>def async
  AsyncProxy.new(self)
end
</code></pre>

<p>  end</p>

<p>  class AsyncProxy</p>

<pre><code>def initialize(job)
  @job = job
end

def perform(*args)
  @job.class.perform_async(*args) # &lt;---- Execute the job
end
</code></pre>

<p>  end
end</p>

<p>```</p>

<p>Lastly, the tests:</p>

<p>```
ress ENTER or type command to continue
bundle exec rake test TEST=&ldquo;test/sucker_punch/async_syntax_test.rb&rdquo;
Run options: &mdash;seed 43886</p>

<h1>Running:</h1>

<p>.</p>

<p>1 runs, 1 assertions, 0 failures, 0 errors, 0 skips
```</p>

<p>Success!</p>

<p>Just like that, new users of Sucker Punch will be able to add <code>require 'sucker_punch/async_syntax'</code> to their projects to use the old syntax. This will allow existing projects using Sucker Punch to take advantage of the reworked internals without the need to make sweeping changes to the enqueueing syntax.</p>

<p>Support for the old syntax will be available for foreseeable future via this include. All new code/applications should use the new syntax going forward.</p>

<h2>Conclusion</h2>

<p>Before realizing a proxy object would work, I tinkered with <code>alias_method</code> and a handful of other approaches to latching on to the job&rsquo;s <code>perform</code> method and saving it off to execute later. While some combinations of these might have worked, the proxy object solution is simple and elegant. There&rsquo;s no magic, which means less maintenance going forward. The last thing I want is to make a breaking change, add support for the old syntax and find the support to be bug-ridden.</p>

<p>Ruby is incredibly flexible. Sometimes a 9-line class is enough to get the job done without reaching for an overly complex metaprogramming approach.</p>

<p>Having said all that, <a href="https://github.com/brandonhilkert/sucker_punch">Sucker Punch <code>v2</code> has been
released</a>!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Lessons Learned from Building a Ruby Gem API]]></title>
    <link href="http://brandonhilkert.com/blog/lessons-learned-from-building-a-ruby-gem-api/"/>
    <updated>2016-01-04T13:12:00-05:00</updated>
    <id>http://brandonhilkert.com/blog/lessons-learned-from-building-a-ruby-gem-api</id>
    <content type="html"><![CDATA[<p>Sucker Punch was created because I had a <a href="http://brandonhilkert.com/blog/why-i-wrote-the-sucker-punch-gem/">need for background processing without a separate worker</a>. But I also figured others did too, given that adding a worker dyno on Heroku was $35. For hobby apps, this was a significant cost.</p>

<p>Having gotten familiar with Celluloid from my work on Sidekiq, I knew Celluloid had all the pieces to puzzle to make this easier. In fact, one of the earliest incarnations of Sucker Punch wasn&rsquo;t a gem at all, just some Ruby classes implementing the pieces of Celluloid necessary to put together a background processing queue.</p>

<!--more-->


<p>The resulting code was less than ideal. It worked, but didn&rsquo;t feel like an API that anyone would want to use. From a beginner&rsquo;s perspective, this would stop adoption in its tracks. This is a common challenge with any code we encounter. No doubt, the Ruby standard library has all the tools necessary to make just about anything we can dream of, but sometimes the result isn&rsquo;t ideal. It&rsquo;s the same reason libraries like Rspec and HTTParty can exist. Developers prefer to use simplistic <a href="https://en.wikipedia.org/wiki/Domain-specific_language">DSLs</a> over convoluted, similarly-functioning code. Ruby has always been a language where developers consistently tout their ability to write code that reads well, feeding the levels of developer happiness.</p>

<h2>Why Rewrite Sucker Punch</h2>

<p>It started when <a href="https://github.com/brandonhilkert/sucker_punch/issues/122">a version of Celluloid was yanked from RubyGems.org</a>. This resulted in a flurry of tweets and GH issues detailing their inability to bundle their applications.</p>

<p>As of version <code>0.17</code>, methods in public API changed without supporting documentation. On top of that, the core <code>celluloid</code> gem was split in to a series of child gems causing navigation to be painful.</p>

<p>This made my life as the Sucker Punch maintainer difficult. There were some requests to upgrade Sucker Punch to use Celluloid <code>~&gt; 0.17</code> and I feared of what would happen if I did. This caused me to think about what the future of Sucker Punch looked like without Celluloid. I still use Sucker Punch and believe it&rsquo;s a valuable asset to the community. My goal was to find a way to move it forward productively without experiencing similar pains.</p>

<p>In the end, thanks to some <a href="https://github.com/brandonhilkert/sucker_punch/pull/126">communinity contributions</a>, <a href="https://github.com/brandonhilkert/sucker_punch/blob/master/CHANGES.md#160">Sucker Punch <code>1.6.0</code> was released with Celluloid <code>0.17.2</code> support</a>.</p>

<h2>Where to now?</h2>

<p>Around that same time, Mike Perham had been writing about his experiences <a href="http://www.mikeperham.com/2015/10/14/optimizing-sidekiq/">optimizing Sidekiq</a> and <a href="http://www.mikeperham.com/2015/10/14/should-you-use-celluloid/">whether continuing with Celluloid made sense for Sidekiq</a>. Having less experience with multi-threading, it didn&rsquo;t make sense for me to reinvent the wheel.</p>

<p>I had been hearing about <a href="https://github.com/ruby-concurrency/concurrent-ruby"><code>concurrent-ruby</code></a> through a variety of outlets, one of which was Rails <a href="https://github.com/rails/rails/pull/20866">replacing the existing concurrency latch with similar functionality from <code>concurrent-ruby</code></a>. After poking around <code>concurrent-ruby</code>, I realized it had all the tools necessary to build a background job processing library. Much like Celluloid in that respect, had the tools, but lacked the simple DSL for the use case.</p>

<p>What if Sucker Punch used <code>concurrent-ruby</code> in place of <code>celluloid</code>?</p>

<p>I can hear what you&rsquo;re thinking&hellip;&ldquo;What&rsquo;s the difference? You&rsquo;re swapping one dependency for another!&rdquo;. 100% true. The difference was that the little bit of communication I had with the maintainers of <code>concurrent-ruby</code> felt comfortable, easy, and welcoming. And with <code>concurrent-ruby</code> now a dependency of Rails, it&rsquo;s even more accessible for those using Sucker Punch within a Rails application (a common use case). But like before, there&rsquo;s no way to be sure that  <code>concurrent-ruby</code> won&rsquo;t cause similar pains/frustrations.</p>

<h2>Celluloid Basics</h2>

<p>A basic Sucker Punch job looks like:</p>

<p>```
class LogJob
  include SuckerPunch::Job</p>

<p>  def perform(event)</p>

<pre><code>Log.new(event).track
</code></pre>

<p>  end
end
```</p>

<p>To run the job asynchronously, we use the following syntax:</p>

<p><code>
LogJob.new.async.perform("new_user")
</code></p>

<p>The most interesting part of this method chain is the <code>async</code>. Removing <code>async</code>, leaves us with a call to a regular instance method.</p>

<p>It so happens that <a href="https://github.com/celluloid/celluloid/wiki/Basic-usage"><code>async</code> is a method in Celluloid that causes the next method to execute asynchronously</a>. And this works because by including <code>SuckerPunch::Job</code>, we&rsquo;re including <code>Celluloid</code>, which gives us the <code>async</code> method on instances of the job class.</p>

<h2>Developing APIs</h2>

<p>If you&rsquo;re familiar with the basics of Celluloid, you&rsquo;ll notice there&rsquo;s not much to Sucker Punch. It adds the Celluloid functionality to job classes and does some things under the hood to ensure there&rsquo;s one queue for each job class.</p>

<p><strong>Early in my <code>concurrent-ruby</code> spike, I realized what a mistake to tie Sucker Punch&rsquo;s API to the API of Celluloid</strong>. Tinkering with the idea of removing Celluloid has left Sucker Punch with two options:</p>

<ol>
<li>Continue using the <code>async</code> method with the new dependency</li>
<li>Break the existing DSL and create a dependency-independent syntax and try my best to document and support the change through the backwards-incompatible change</li>
</ol>


<p>Option 1 is the easy way out. Option 2 is more work, far more scary, but the right thing to do.</p>

<p>I decided to abandon my thoughts about previous versions and write as if it were new today. This will be the basis for the next major release of Sucker Punch (<code>2.0.0</code>).</p>

<p>Settling on abandoning the existing API, the next question is, <strong>&ldquo;What should the new API look like?&rdquo;</strong>.</p>

<p>Being a fan of Sidekiq, it didn&rsquo;t take long for me to realize it could actually make developers lives easier if Sucker Punch&rsquo;s API was the same.</p>

<p>Switching between Sidekiq and Sucker Punch is not uncommon. I look at Sidekiq as Sucker Punch&rsquo;s big brother and often suggest people use it instead when the use case makes sense.</p>

<p>If you&rsquo;re familiar with Sidekiq, using the <code>perform_async</code> class method should look familiar:</p>

<p><code>
LogJob.peform_async("new_user")
</code></p>

<p><strong>So why not use the same for Sucker Punch?</strong></p>

<p>If so, switching between Sidekiq and Sucker Punch would be no more than swapping <code>include Sidekiq::Worker</code> for <code>include SuckerPunch::Job</code> in the job class, aside from the gem installation itself. The result would be less context switching and more opportunity focus on the important parts of the application.</p>

<p>I can hear the same question again, &ldquo;What&rsquo;s the difference? You suggested isolating yourself from a dependency&rsquo;s API and now you&rsquo;re suggesting using another!&rdquo;. I look at this one a little differently&hellip;</p>

<p>Sidekiq is uniquely positioned in the community as a paid open source project. We&rsquo;re happy users of Sidekiq Pro and continue to do so for the support. You can certainly get support for the open source version, but one way to ensure Sidekiq is actively maintained is by paying for it. This financial support from us and others decreases the likelihood Mike will choose to abandon it. Mike&rsquo;s also been public about his long-term interest in maintaining Sidekiq. With all this in mind, I&rsquo;m willing to bank on its existence as the defacto way to enqueue jobs for background processing.</p>

<p>And if for some reason Sidekiq does disappear, there&rsquo;s nothing lost on Sucker Punch. There&rsquo;s no dependency. Just a similar syntax.</p>

<p>Sucker Punch <code>2.0.0</code> will have 2 class methods to enqueue jobs:</p>

<p><code>
LogJob.perform_async("new_user")
</code></p>

<p>and</p>

<p><code>
LogJob.perform_in(5.minutes, "new_user")
</code></p>

<p>The latter defining a delayed processing of the <code>perform</code> method 5 minutes from now.</p>

<h2>Summary</h2>

<p>Settling on a library&rsquo;s API isn&rsquo;t easy. Isolating it from underlying dependencies is the best bet for long-term stability. Using the <a href="https://en.wikipedia.org/wiki/Adapter">adapter pattern</a> can help create a layer (adapter) between your code and the dependency&rsquo;s API. But like always, there are always exceptions.</p>

<p>I&rsquo;m taking a leap of faith that doing what I believe is right won&rsquo;t leave existing users frustrated, ultimately abandoning Sucker Punch altogether.</p>

<p>Sucker Punch <code>v2.0</code> is shaping up to be the best release yet. I&rsquo;m looking forward to sharing it with you.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sidekiq As A Microservice Message Queue]]></title>
    <link href="http://brandonhilkert.com/blog/sidekiq-as-a-microservice-message-queue/"/>
    <updated>2015-11-30T12:06:00-05:00</updated>
    <id>http://brandonhilkert.com/blog/sidekiq-as-a-microservice-message-queue</id>
    <content type="html"><![CDATA[<p>In the recent series on transitioning to microservices, I detailed a path to move a large legacy Rails monolith to a cluster of a dozen microservices. But not everyone starts out with a legacy monolith. In fact, given Rails popularity amongst startups, <strong>it&rsquo;s likely most Rails applications don&rsquo;t live to see 4+ years in production</strong>. So what if we don&rsquo;t have a huge monolith on our hands? Are microservices still out of the question?</p>

<p>Sadly, the answer is, &ldquo;it depends&rdquo;. The &ldquo;depends&rdquo; part is specific to your context. While microservices may seem like the right move for you and your application, it&rsquo;s also possible it could cause a mess if not done carefully.</p>

<!--more-->


<p>This post will explore opportunities for splitting out unique microservices using <a href="http://sidekiq.org/">Sidekiq</a>, without introducing an enterprise message broker like <a href="https://www.rabbitmq.com/">RabbitMQ</a> or <a href="http://kafka.apache.org/">Apache Kafka</a>.</p>

<h2>When are Microservices right?</h2>

<p>Martin Fowler <a href="http://martinfowler.com/articles/microservice-trade-offs.html">wrote about trade-offs that come when introducing microservices</a>.</p>

<p>The article outlines 6 pros and cons introduced when you moved a microservices-based architecture. The strongest argument for microservices is the strengthening of module boundaries.</p>

<p>Module boundaries are naturally strengthened when we&rsquo;re forced to move code to another codebase. The result being, in most cases a group of microservices appears to be better constructed than the legacy monolith it was extracted from.</p>

<p>There&rsquo;s no doubt Rails allows developers to get something up and running very quickly. Sadly, you can do so while making a big mess at the same time. It&rsquo;s worth noting there&rsquo;s nothing stopping a monolith from being well constructed. With some discipline, <a href="https://www.youtube.com/watch?v=KJVTM7mE1Cc">your monolith can be the bright and shiny beauty that DHH wants it to be</a>.</p>

<h2>Sidekiq Queues</h2>

<p>Ok, ok. You get it. Microservices can be awesome, but they can also make a big mess. I want to tell you about how I recently avoided a big mess without going &ldquo;all in&rdquo;.</p>

<p>There&rsquo;s no hiding I&rsquo;m a huge <a href="http://sidekiq.org/">Sidekiq</a> fan. It&rsquo;s my goto solution for background processing.</p>

<p>Sidekiq has the notion of <a href="https://github.com/mperham/sidekiq/wiki/Advanced-Options#workers">named queues</a> for both <a href="https://github.com/mperham/sidekiq/wiki/Advanced-Options#workers">jobs</a> and <a href="https://github.com/mperham/sidekiq/wiki/Advanced-Options#queues">workers</a>. This is great from the standpoint that it allows you to put that unimportant long-running job in a different queue without delayed other important fast-running jobs.</p>

<p>A typical worker might look like:</p>

<p>```
class ImportantWorker
  include Sidekiq::Worker</p>

<p>  def perform(id)</p>

<pre><code># Do the important stuff
</code></pre>

<p>  end
end
```</p>

<p>If we want to send this job to a different queue, we&rsquo;d add <code>sidekiq_options queue: :important</code> to the worker, resulting in:</p>

<p>```
class ImportantWorker
  include Sidekiq::Worker
  sidekiq_options queue: :important</p>

<p>  def perform(id)</p>

<pre><code># Do the important stuff
</code></pre>

<p>  end
end
```</p>

<p>Now, we need to make sure the worker process that&rsquo;s running the jobs knows to process jobs off this queue. A typical worker might be invoked with:</p>

<p><code>
bin/sidekiq
</code></p>

<p>Since new jobs going through this worker will end up on the <code>important</code> queue, we want to make sure the worker is processing jobs from the <code>important</code> queue too:</p>

<p><code>
bin/sidekiq -q important -q default
</code></p>

<p><em>Note: Jobs that don&rsquo;t specify a queue will go to the <code>default</code> queue. We have to include the <code>default</code> queue when we using the <code>-q</code> option, otherwise the default queue will be ignored in favor of the queue passed to the <code>-q</code> option.</em></p>

<p>The best part, you don&rsquo;t even have to have multiple worker processes to process jobs from multiple queues. Furthermore, the <code>important</code> queue can be checked twice as often as the <code>default</code> queue:</p>

<p><code>
bin/sidekiq -q important,2 -q default
</code></p>

<p>This flexibility of where jobs are enqueued and how they&rsquo;re processed gives us an incredible amount of freedom when building our applications.</p>

<h2>Extracting Worker to a Microservice</h2>

<p>Let&rsquo;s assume that we&rsquo;ve deployed your main application to Heroku. The application uses Sidekiq and we&rsquo;ve included a Redis add-on. With the addition of the add-on, our application now has a <code>REDIS_URL</code> environment variable that Sidekiq connects to on startup. We have a web process, and worker process. A pretty standard Rails stack:</p>

<p><img class="center" src="/images/sidekiq/rails-web-worker.png" title="&ldquo;Rails with typical worker process&rdquo;" ></p>

<p><strong>What&rsquo;s stopping us from using that same <code>REDIS_URL</code> in another application?</strong></p>

<p>Nothing, actually. And if we consider what we know about the isolation of jobs in queue and workers working on specific queues, there&rsquo;s nothing stopping us from having workers for a specific queue in a different application altogether.</p>

<p>Remember <code>ImportantWorker</code>, imagine the logic for that job was better left for a different application. We&rsquo;ll leave that part a little hand-wavey because there still should be a really good reason to do so. But we&rsquo;ll assume you&rsquo;ve thought long and hard about this and decided the core application was not a great place for this job logic.</p>

<p>Extracting the worker a separate application might now look something like this:</p>

<p><img class="center" src="/images/sidekiq/rails-with-microservice.png" title="&ldquo;Using Sidekiq as a Message Queue between two Rails microservices&rdquo;" ></p>

<h2>Enqueueing Jobs with the Sidekiq Client</h2>

<p>Typically, to enqueue the <code>ImportantWorker</code> above, we&rsquo;d call the following from our application:</p>

<p><code>
ImportantWorker.perform_async(1)
</code></p>

<p>This works great when <code>ImportantWorker</code> is defined in our application. With the expanded stack above, <code>ImportantWorker</code> now lives in a new microservice, which means we don&rsquo;t have access to the <code>ImportantWorker</code> class from within the application. We <em>could</em> define it in the application just so we can enqueue it, with the intent that the application won&rsquo;t process jobs for that worker, but that feels funny to me.</p>

<p>Rather, we can turn to the underlying Sidekiq client API to enqueue the job instead:</p>

<p>```
Sidekiq::Client.push(
  &ldquo;class&rdquo; => &ldquo;ImportantWorker&rdquo;,
  &ldquo;queue&rdquo; => &ldquo;important&rdquo;,
  &ldquo;args&rdquo; => [1]
)</p>

<p>```</p>

<p><em>Note: We have to be sure to define the <code>class</code> as a string <code>"ImportantWorker"</code>, otherwise we&rsquo;ll get an exception during enqueuing because the worker isn&rsquo;t defined in the application.</em></p>

<h2>Processing Sidekiq Jobs from a Microservice</h2>

<p>Now we&rsquo;re pushing jobs to the <code>important</code> queue, but have nothing in our application to process them. In fact, our worker process isn&rsquo;t even looking at that queue:</p>

<p><code>
bin/sidekiq -q default
</code></p>

<p>From our microservice, we setup a worker process to <strong>ONLY</strong> look at the <code>important</code> queue:</p>

<p><code>
bin/sidekiq -q important
</code></p>

<p>We define the <code>ImportantWorker</code> in our microservice:</p>

<p>```
class ImportantWorker
  include Sidekiq::Worker
  sidekiq_options queue: :important</p>

<p>  def perform(id)</p>

<pre><code># Do the important stuff
</code></pre>

<p>  end
end
```</p>

<p>And now when the worker picks jobs out of the <code>important</code> queue, it&rsquo;ll process them using the <code>ImportantWorker</code> defined above in our microservice.</p>

<p>If we wanted to go one step further, the microservice could then enqueue a job using the Sidekiq client API to a queue that only the core application is working on in order to send communication back the other direction.</p>

<h2>Summary</h2>

<p>Any architectural decision has risks. Microservices are no exception. Microservices can be easier than an enterprise message broker, cluster of new servers and a handful of devops headaches.</p>

<p>I originally dubbed this the &ldquo;poor man&rsquo;s message bus&rdquo;. With more thought, there&rsquo;s nothing &ldquo;poor&rdquo; about this. Sidekiq has a been a reliable piece of our infrastructure and I have no reason to believe that&rsquo;ll change, even if we are using it for more than just simple background processing from a single application.</p>
]]></content>
  </entry>
  
</feed>

<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: rails | Brandon Hilkert]]></title>
  <link href="http://brandonhilkert.com/blog/categories/rails/atom.xml" rel="self"/>
  <link href="http://brandonhilkert.com/"/>
  <updated>2016-05-22T09:02:11-04:00</updated>
  <id>http://brandonhilkert.com/</id>
  <author>
    <name><![CDATA[Brandon Hilkert]]></name>
    <email><![CDATA[brandonhilkert@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Rails Progress Indicator Using Nprogress]]></title>
    <link href="http://brandonhilkert.com/blog/rails-progress-indicator-using-nprogress/"/>
    <updated>2016-04-29T09:44:00-04:00</updated>
    <id>http://brandonhilkert.com/blog/rails-progress-indicator-using-nprogress</id>
    <content type="html"><![CDATA[<p>Contrary to popular opinion, I&rsquo;m a fan of <a href="https://github.com/turbolinks/turbolinks">Turbolinks</a>. I leave it enabled in all my Rails applications. Most of the negative opinions I hear relate to it &ldquo;breaking&rdquo; third-party jQuery plugins. I say &ldquo;breaking&rdquo; because it&rsquo;s <em>really</em> not changing the plugin&rsquo;s behavior, it just requires the plugin to be initialized differently. If you&rsquo;re upgrading to a newer version of Rails and have a bunch of legacy JavaScript code, I can imagine this being difficult. But if you&rsquo;re green-fielding a new application, there&rsquo;s no reason not to take advantage of it. I wrote extensively about <a href="http://brandonhilkert.com/blog/organizing-javascript-in-rails-application-with-turbolinks/">how to organize JavaScript in a Rails application with Turbolinks enabled</a>. If you&rsquo;re struggling to get your JavaScript code to work as expected on clicks through the application, take a look at that post. I continue to use that organization pattern for all my applications and it never lets me down.</p>

<p>With Turbolinks enabled, interacting with an application feels smooth and fast. No more full page refreshes.</p>

<p>Every once in awhile we&rsquo;ll stumble on a page request takes longer than others. Rather than having the user sit there thinking nothing is happening, we can offer better feedback through a loading progress bar, specifically <a href="http://ricostacruz.com/nprogress/">nprogress</a>. I use <code>nprogress</code> in all my applications. I&rsquo;ve found it to be the perfect companion to Turbolinks to create a great user experience.</p>

<h2>The Problem</h2>

<p>In a traditional web application, when we click a link or submit a form, we get a loading spinner where the favicon typically appears. We might also see text in the status bar saying &ldquo;Connecting&hellip;&rdquo; or &ldquo;Loading&hellip;&rdquo;. These are the loading indications that internet users have become accustomed to.</p>

<p>By adopting Turbolinks, we not longer get those loading feedback mechanisms because the request for the new page is asynchronous. Once the request is complete, the new content is rendered in place of the previous page&rsquo;s body element. For fast page loads, this isn&rsquo;t a problem. However, if you have applications like mine, every once in awhile, you might have a page request take a few seconds (reasons for this are beyond the scope of this article). In those cases, a user might click a link and sit there for 2-3 sec. without any indication the page is loading. While Turbolinks generally improves the user experience of our application, having no user feedback for several seconds is not ideal (ideally, you&rsquo;d want to address a page request that takes multiple seconds). This is where <code>nprogress</code> can help.</p>

<h2>The Solution</h2>

<p><a href="http://ricostacruz.com/nprogress/"><code>nprogress</code></a> is a progress loading indicator, like what you see on YouTube.</p>

<p>Like other JavaScript libraries, there&rsquo;s <a href="https://github.com/caarlos0/nprogress-rails">a Ruby Gem that vendors the code and includes it in the Rails asset pipeline</a>.</p>

<p>We&rsquo;ll first add <code>nprogress-rails</code> to our Gemfile:</p>

<p><code>
gem "nprogress-rails"
</code></p>

<p>Bundle to install the new gem:</p>

<p><code>
$ bundle install
</code></p>

<p>Now with <code>nprogress</code> installed, we need to include the JavaScript in our application. We&rsquo;ll do this by adding the following the <code>app/assets/javascripts/application.js</code> manifest:</p>

<p><code>
//= require nprogress
//= require nprogress-turbolinks
</code></p>

<p>We first include the <code>nprogress</code> JavaScript source, and then an adapter that&rsquo;ll hook the Turbolinks request to the progress indicator.</p>

<p><em>Note: If you&rsquo;re familiar with Turbolinks and its events, you&rsquo;ll recognize the <a href="https://github.com/caarlos0/nprogress-rails/blob/master/app/assets/javascripts/nprogress-turbolinks.js">events triggered</a>.</em></p>

<p>By default, the <code>nprogress</code> loading bar is anchored to the top of the browser window, but we need to include some CSS to make this work. Let&rsquo;s open the <code>app/assets/stylesheets/application.scss</code> manifest file and add the following:</p>

<p><code>
*= require nprogress
*= require nprogress-bootstrap
</code></p>

<p><em>Note: Including <code>nprogress-bootstrap</code> isn&rsquo;t necessary if you don&rsquo;t use <a href="http://getbootstrap.com/css/">Bootstrap</a> in your application. I typically do, so I&rsquo;m going to inclue it.</em></p>

<p>At this point, we&rsquo;ll have a working loading indicator. But what if we want to tweak the styles to match your application&rsquo;s theme?</p>

<h2>Customizing Nprogress Styles</h2>

<p>Because the <a href="https://github.com/caarlos0/nprogress-rails/blob/master/app/assets/stylesheets/nprogress.scss#L1"><code>nprgress</code> styles are Sass</a>, we can overwrite the variables for customization.</p>

<p>There are 3 variables available to overwite:</p>

<ul>
<li><code>$nprogress-color</code></li>
<li><code>$nprogress-height</code></li>
<li><code>$nprogress-zindex</code></li>
</ul>


<p>For <a href="https://www.bark.us/">Bark</a>, we have an aqua accent color with use throughout the site. It made sense for the <code>nprogress</code> loading indicator to be that same color.</p>

<p>Back in our <code>app/assets/stylesheets/application.scss</code>, I overwrote the variable before including the <code>nprogress</code> source code:</p>

<p>```
$nprogress-color: #37c8c9;</p>

<p>@import &ldquo;nprogress&rdquo;;
@import &ldquo;nprogress-bootstrap&rdquo;;
```</p>

<h2>Summary</h2>

<p>I&rsquo;ve found <code>nprogress</code> to be a great companion library to Turbolinks. The two libraries together provide a much better user experience over full page refreshes. Turbolinks helps asynchronously load the page content that&rsquo;s changing and <code>nprogress</code> gives the user feedback that their request is in progress. Now, even when a user has to suffer through multi-second page loads, at least they&rsquo;ll know it&rsquo;s not broken and don&rsquo;t have to click again.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sidekiq As A Microservice Message Queue]]></title>
    <link href="http://brandonhilkert.com/blog/sidekiq-as-a-microservice-message-queue/"/>
    <updated>2015-11-30T12:06:00-05:00</updated>
    <id>http://brandonhilkert.com/blog/sidekiq-as-a-microservice-message-queue</id>
    <content type="html"><![CDATA[<p>In the recent series on transitioning to microservices, I detailed a path to move a large legacy Rails monolith to a cluster of a dozen microservices. But not everyone starts out with a legacy monolith. In fact, given Rails popularity amongst startups, <strong>it&rsquo;s likely most Rails applications don&rsquo;t live to see 4+ years in production</strong>. So what if we don&rsquo;t have a huge monolith on our hands? Are microservices still out of the question?</p>

<p>Sadly, the answer is, &ldquo;it depends&rdquo;. The &ldquo;depends&rdquo; part is specific to your context. While microservices may seem like the right move for you and your application, it&rsquo;s also possible it could cause a mess if not done carefully.</p>

<!--more-->


<p>This post will explore opportunities for splitting out unique microservices using <a href="http://sidekiq.org/">Sidekiq</a>, without introducing an enterprise message broker like <a href="https://www.rabbitmq.com/">RabbitMQ</a> or <a href="http://kafka.apache.org/">Apache Kafka</a>.</p>

<h2>When are Microservices right?</h2>

<p>Martin Fowler <a href="http://martinfowler.com/articles/microservice-trade-offs.html">wrote about trade-offs that come when introducing microservices</a>.</p>

<p>The article outlines 6 pros and cons introduced when you moved a microservices-based architecture. The strongest argument for microservices is the strengthening of module boundaries.</p>

<p>Module boundaries are naturally strengthened when we&rsquo;re forced to move code to another codebase. The result being, in most cases a group of microservices appears to be better constructed than the legacy monolith it was extracted from.</p>

<p>There&rsquo;s no doubt Rails allows developers to get something up and running very quickly. Sadly, you can do so while making a big mess at the same time. It&rsquo;s worth noting there&rsquo;s nothing stopping a monolith from being well constructed. With some discipline, <a href="https://www.youtube.com/watch?v=KJVTM7mE1Cc">your monolith can be the bright and shiny beauty that DHH wants it to be</a>.</p>

<h2>Sidekiq Queues</h2>

<p>Ok, ok. You get it. Microservices can be awesome, but they can also make a big mess. I want to tell you about how I recently avoided a big mess without going &ldquo;all in&rdquo;.</p>

<p>There&rsquo;s no hiding I&rsquo;m a huge <a href="http://sidekiq.org/">Sidekiq</a> fan. It&rsquo;s my goto solution for background processing.</p>

<p>Sidekiq has the notion of <a href="https://github.com/mperham/sidekiq/wiki/Advanced-Options#workers">named queues</a> for both <a href="https://github.com/mperham/sidekiq/wiki/Advanced-Options#workers">jobs</a> and <a href="https://github.com/mperham/sidekiq/wiki/Advanced-Options#queues">workers</a>. This is great from the standpoint that it allows you to put that unimportant long-running job in a different queue without delayed other important fast-running jobs.</p>

<p>A typical worker might look like:</p>

<p>```
class ImportantWorker
  include Sidekiq::Worker</p>

<p>  def perform(id)</p>

<pre><code># Do the important stuff
</code></pre>

<p>  end
end
```</p>

<p>If we want to send this job to a different queue, we&rsquo;d add <code>sidekiq_options queue: :important</code> to the worker, resulting in:</p>

<p>```
class ImportantWorker
  include Sidekiq::Worker
  sidekiq_options queue: :important</p>

<p>  def perform(id)</p>

<pre><code># Do the important stuff
</code></pre>

<p>  end
end
```</p>

<p>Now, we need to make sure the worker process that&rsquo;s running the jobs knows to process jobs off this queue. A typical worker might be invoked with:</p>

<p><code>
bin/sidekiq
</code></p>

<p>Since new jobs going through this worker will end up on the <code>important</code> queue, we want to make sure the worker is processing jobs from the <code>important</code> queue too:</p>

<p><code>
bin/sidekiq -q important -q default
</code></p>

<p><em>Note: Jobs that don&rsquo;t specify a queue will go to the <code>default</code> queue. We have to include the <code>default</code> queue when we using the <code>-q</code> option, otherwise the default queue will be ignored in favor of the queue passed to the <code>-q</code> option.</em></p>

<p>The best part, you don&rsquo;t even have to have multiple worker processes to process jobs from multiple queues. Furthermore, the <code>important</code> queue can be checked twice as often as the <code>default</code> queue:</p>

<p><code>
bin/sidekiq -q important,2 -q default
</code></p>

<p>This flexibility of where jobs are enqueued and how they&rsquo;re processed gives us an incredible amount of freedom when building our applications.</p>

<h2>Extracting Worker to a Microservice</h2>

<p>Let&rsquo;s assume that we&rsquo;ve deployed your main application to Heroku. The application uses Sidekiq and we&rsquo;ve included a Redis add-on. With the addition of the add-on, our application now has a <code>REDIS_URL</code> environment variable that Sidekiq connects to on startup. We have a web process, and worker process. A pretty standard Rails stack:</p>

<p><img class="center" src="/images/sidekiq/rails-web-worker.png" title="&ldquo;Rails with typical worker process&rdquo;" ></p>

<p><strong>What&rsquo;s stopping us from using that same <code>REDIS_URL</code> in another application?</strong></p>

<p>Nothing, actually. And if we consider what we know about the isolation of jobs in queue and workers working on specific queues, there&rsquo;s nothing stopping us from having workers for a specific queue in a different application altogether.</p>

<p>Remember <code>ImportantWorker</code>, imagine the logic for that job was better left for a different application. We&rsquo;ll leave that part a little hand-wavey because there still should be a really good reason to do so. But we&rsquo;ll assume you&rsquo;ve thought long and hard about this and decided the core application was not a great place for this job logic.</p>

<p>Extracting the worker a separate application might now look something like this:</p>

<p><img class="center" src="/images/sidekiq/rails-with-microservice.png" title="&ldquo;Using Sidekiq as a Message Queue between two Rails microservices&rdquo;" ></p>

<h2>Enqueueing Jobs with the Sidekiq Client</h2>

<p>Typically, to enqueue the <code>ImportantWorker</code> above, we&rsquo;d call the following from our application:</p>

<p><code>
ImportantWorker.perform_async(1)
</code></p>

<p>This works great when <code>ImportantWorker</code> is defined in our application. With the expanded stack above, <code>ImportantWorker</code> now lives in a new microservice, which means we don&rsquo;t have access to the <code>ImportantWorker</code> class from within the application. We <em>could</em> define it in the application just so we can enqueue it, with the intent that the application won&rsquo;t process jobs for that worker, but that feels funny to me.</p>

<p>Rather, we can turn to the underlying Sidekiq client API to enqueue the job instead:</p>

<p>```
Sidekiq::Client.push(
  &ldquo;class&rdquo; => &ldquo;ImportantWorker&rdquo;,
  &ldquo;queue&rdquo; => &ldquo;important&rdquo;,
  &ldquo;args&rdquo; => [1]
)</p>

<p>```</p>

<p><em>Note: We have to be sure to define the <code>class</code> as a string <code>"ImportantWorker"</code>, otherwise we&rsquo;ll get an exception during enqueuing because the worker isn&rsquo;t defined in the application.</em></p>

<h2>Processing Sidekiq Jobs from a Microservice</h2>

<p>Now we&rsquo;re pushing jobs to the <code>important</code> queue, but have nothing in our application to process them. In fact, our worker process isn&rsquo;t even looking at that queue:</p>

<p><code>
bin/sidekiq -q default
</code></p>

<p>From our microservice, we setup a worker process to <strong>ONLY</strong> look at the <code>important</code> queue:</p>

<p><code>
bin/sidekiq -q important
</code></p>

<p>We define the <code>ImportantWorker</code> in our microservice:</p>

<p>```
class ImportantWorker
  include Sidekiq::Worker
  sidekiq_options queue: :important</p>

<p>  def perform(id)</p>

<pre><code># Do the important stuff
</code></pre>

<p>  end
end
```</p>

<p>And now when the worker picks jobs out of the <code>important</code> queue, it&rsquo;ll process them using the <code>ImportantWorker</code> defined above in our microservice.</p>

<p>If we wanted to go one step further, the microservice could then enqueue a job using the Sidekiq client API to a queue that only the core application is working on in order to send communication back the other direction.</p>

<h2>Summary</h2>

<p>Any architectural decision has risks. Microservices are no exception. Microservices can be easier than an enterprise message broker, cluster of new servers and a handful of devops headaches.</p>

<p>I originally dubbed this the &ldquo;poor man&rsquo;s message bus&rdquo;. With more thought, there&rsquo;s nothing &ldquo;poor&rdquo; about this. Sidekiq has a been a reliable piece of our infrastructure and I have no reason to believe that&rsquo;ll change, even if we are using it for more than just simple background processing from a single application.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Path to Services - Part 3 - Synchronous Events]]></title>
    <link href="http://brandonhilkert.com/blog/a-path-to-services-part-3-synchronous-events/"/>
    <updated>2015-10-15T09:07:00-04:00</updated>
    <id>http://brandonhilkert.com/blog/a-path-to-services-part-3-synchronous-events</id>
    <content type="html"><![CDATA[<p><em>This article was originally posted on the <a href="http://plumbing.pipelinedeals.com/">PipelineDeals Engineering
Blog</a></em></p>

<p>In the <a href="/blog/a-path-to-services-part-1-start-small/">previous article in this series</a>, we introduced a billing service to determine which features an account could access. If you remember, <a href="/our-path-to-services-part-1-start-small/">the email service</a> was a &ldquo;fire and forget&rdquo; operation and was capable of handling throughput delays given its low value to the core application.</p>

<p>This post will explore how we handle synchronous communication for a service like billing where an inline response is required to service a request from the core application.</p>

<!--more-->


<h2>Background</h2>

<p>If you remember from the previous post, we introduced the billing service to an infrastructure that looked like this:</p>

<p><img class="center" src="/images/services/app-email-billing.png" title="&ldquo;Web application with Email and Billing Microservice&rdquo;" ></p>

<p>Handling multiple pricing tiers in a SaaS app means you have to control authorization based on account status. Our billing service encapsulates the knowledge of which features correspond to which pricing tier.</p>

<p>For instance, one feature is the ability to send trackable email to contacts in your PipelineDeals account. To service this request, we add an option to the bulk action menu from a list view:</p>

<p><img class="center" src="/images/services/send-email.png" title="&ldquo;Send email feature&rdquo;" ></p>

<h2>Service Request</h2>

<p>Before we can conditionally show this option based on the pricing tier, we have to first make a request to the billing service to get the list of features available to that user.</p>

<p>```
class Billing::Features
  def initialize(user)</p>

<pre><code>@user = user
@account = user.account
</code></pre>

<p>  end</p>

<p>  def list</p>

<pre><code>Rails.cache.fetch("account_#{account.id}_billing_features") do
  response = Billing::Api.get "account/#{account.id}/features"
  response['features']
end
</code></pre>

<p>  end</p>

<p>  private</p>

<p>  attr_reader :user, :account
end
```</p>

<p><code>Billing::Api</code>, in this case, is a wrapper around the API calls to handle exceptions and other information like security.</p>

<p><em>Note: When making synchronous HTTP calls like this, it&rsquo;s worth considering the failure state and providing a default response set in that case so the user isn&rsquo;t burdened with a failure page. In this case, one option would be dumb down the features on the page to the most basic tier.</em></p>

<h2>Serving a JSON API</h2>

<p>Plenty of articles have been written about how to create a JSON API with Rails, so we won&rsquo;t rehash those techniques here. Instead, we&rsquo;ll highlight patterns we&rsquo;ve used for consistency.</p>

<p>We tend to reserve the root URL namespace for UI-related routes, so we start by creating a unique namespace for the API:</p>

<p>```
namespace :api do
  resources :account do</p>

<pre><code>resource :features, only: :show
</code></pre>

<p>  end
end
```</p>

<p>This setup gives us the path <code>/api/account/:account_id/features</code>. We haven&rsquo;t found a need for versioning internal APIs. If we decided to in the future, we could always add the API version as a request header.</p>

<p>The <code>features</code> endpoint looks like:</p>

<p>```
class Api::FeaturesController &lt; Api::ApiController
  skip_before_filter :verify_authenticity_token</p>

<p>  def show</p>

<pre><code>render json: {
  success: true,
  features: AccountFeatures.new(@account_id).list
}
</code></pre>

<p>  end
end
```</p>

<p>Notice <code>Api::FeaturesController</code> inherits from <code>Api::ApiController</code>. We keep the API-related functionality in this base controller so each endpoint will get access to security and response handling commonalities.</p>

<p><code>AccountFeatures</code> is a PORO that knows how to list billing features for a particular account. We could&rsquo;ve queried it straight from an ActiveRecord-based model, but our handling of features is a little more complicated than picking them straight from the database.</p>

<p>Another note here is that we haven&rsquo;t introduced a serializing library like <code>active_model_serializers</code> or <code>jbuilder</code>. Using <code>render json</code> alone has serviced us well for simple APIs. We reach for something more complex when the response has more attributes than shown above.</p>

<h2>Handling Service Response</h2>

<p>By introducing <code>Rails.cache</code>, we can serve requests (after the initial) without requiring a call to the billing service.</p>

<p>One of the first things we do is serialize the set of features to JavaScript so our client-side code has access:</p>

<p><code>
&lt;%= javascript_tag do %&gt;
  window.Features = &lt;%= Billing::Features.new(logged_in_user).list.to_json %&gt;;
&lt;% end %&gt;
</code></p>

<p>We also include a helper module in to our Rails views/controllers, so we can handle conditional feature logic:</p>

<p>```
module Features
  def feature_enabled?(feature)</p>

<pre><code>Billing::Features.new(logged_in_user).list.include?(feature.to_s)
</code></pre>

<p>  end
end
```</p>

<h2>Synchronous Side Effects</h2>

<p>When we <a href="/our-path-to-services-part-2-synchronous-vs-asynchronous/">looked at asynchronous service requests</a>, there was less immediacy associated with the request due to its &ldquo;fire-and-forget&rdquo; nature. A synchronous request, on the other hand, will handle all requests to the core application, so scaling can be challenge and infrastructure costs can add up.</p>

<p><img class="center" src="/images/services/synchronous-service-cost.png" title="&ldquo;Increased cost by introducing synchronous microservice&rdquo;" ></p>

<p>In addition to the infrastructure costs, performance can be a factor. If the original page response time was 100ms and we&rsquo;re adding a synchronous service request that takes another 100ms, all of a sudden we&rsquo;ve doubled our users' response times. And while this architectural decision might seem like an optimization, I&rsquo;m positive none of our users will thank us for making their page load times 2x slower.</p>

<h2>Summary</h2>

<p>As you can see, there&rsquo;s little magic to setting up a synchronous service request.</p>

<p>Challenges appear when you consider failure states at every point in the service communication &ndash; the service could be down, or the HTTP request itself could fail due to network connectivity. As mentioned above, providing a default response during service failure is a great start to increasing the application&rsquo;s reliability. Optionally, <a href="https://en.wikipedia.org/wiki/Circuit_breaker_design_pattern">the circuit break pattern</a> can provide robust handling of network failures.</p>

<p>Part 4 in this series will cover how we manage asynchronous communication between services, specifically around an <a href="https://github.com/PipelineDeals/mantle">open source gem we built called Mantle</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Path to Services - Part 2 - Synchronous vs. Asynchronous]]></title>
    <link href="http://brandonhilkert.com/blog/a-path-to-services-part-2-synchronous-vs-asynchronous/"/>
    <updated>2015-08-14T10:32:00-04:00</updated>
    <id>http://brandonhilkert.com/blog/a-path-to-services-part-2-synchronous-vs-asynchronous</id>
    <content type="html"><![CDATA[<p><em>This article was originally posted on the <a href="http://plumbing.pipelinedeals.com/">PipelineDeals Engineering
Blog</a></em></p>

<p>In the <a href="/blog/a-path-to-services-part-1-start-small/">previous article in this series</a>, we moved the responsibility of emails to a separate Rails application. In order to leverage this new service, we created a PORO to encapsulate the specifics of communicating with our new service by taking advantage of Sidekiq&rsquo;s built-in retry mechanism to protect from intermittent network issues.</p>

<p>Communication between microservices can be broken down in to 2 categories: <strong>synchronous</strong> and  <strong>asynchronous</strong>.
Understanding when to use each is critical in maintaining a healthy infrastructure. This post will explore details about these two methods of communication and their associated use cases.</p>

<!--more-->


<h2>Background</h2>

<p>Continuing the discussion of our architecture from last time, we have a primary
Rails web application serving the majority of our business logic. We now have an additional application that&rsquo;s only responsibility is the formatting and sending of emails.</p>

<p><img class="center" src="/images/services/app-email.png" title="&ldquo;Application service with email microservice&rdquo;" ></p>

<p>In this article, we&rsquo;ll discuss the addition of our Billing service. The service&rsquo;s responsibility to is to process transactions related to money. This can come in the form of a trial conversion, adding a seat to an additional account, or deleting users from an existing account, among others.</p>

<p>Like many SaaS applications, PipelineDeals has multiple tiers of service. The most expensive intended for customers needing advanced functionality. Part of the billing service&rsquo;s responsibility is to manage the knowledge of which features an account can access.</p>

<p>So stepping back to the main PipelineDeals web application, the app has to decide which features to render at page load. Because the billing service is our source of truth for this information, a page load will now require a call to this service to understand which features to render.</p>

<p>This new dependency looks a little different than the email dependency from the
<a href="/blog/a-path-to-services-part-1-start-small/">previous article</a>. Email has the
luxury of not being in the dependency path of a page load. Very few customers
will complain if an email is 10 seconds late. On the other hand, they&rsquo;ll
complain immediately if their account won&rsquo;t load, and rightfully so.</p>

<p><img class="center" src="/images/services/app-email-billing.png" title="&ldquo;Application service include email and billing microservices&rdquo;" ></p>

<p>An interesting benefit from having already extracted the email service is that the billing service sends email regarding financial transactions and account changes. Typically, we would have done the same thing for every other Rails app that needed to send email, which was integrate <code>ActionMailer</code> and setup the templates and mailers needed to do the work. In this case, we can add those emails to the email service and use the same communication patterns we do from the main web application to trigger the sending of an email from the billing service. This does require making changes to 2 different projects for a single feature (business logic in billing and mailer in email), but removes the necessity to configure another app to send email properly. We viewed this as a benefit.</p>

<h2>Asynchronous Events</h2>

<p>As the easier of the two, asynchronous would be any communication not necessary for the request/response cycle to complete. Email is the perfect example. Logging also falls in to this category.</p>

<p>For the networks gurus out there, this would be similar to UDP communication. More of a fire-and-forget approach.</p>

<p>An email, in this case, is triggered due to something like an account sign up.
We send a welcome email thanking the customer for signing up and giving them
some guidance on how to get the most benefit from the application. Somewhere in
the process of signing up, the code triggers an email and passes along the data
needed for email template.</p>

<p>As shown in the previous article, the call to send the email looks something like this:</p>

<p><code>ruby
Email.to current_user, :user_welcome
</code></p>

<p>The value in this call is that under the covers, it&rsquo;s enqueuing a Sidekiq job:</p>

<p><code>ruby
EmailWorker.perform_async(opts)
</code></p>

<p>where <code>opts</code> is a hash of data related to the email and the variables needed for the template.</p>

<p><em>Note: Because the options are serialized to JSON, values in hash must be simple structures. Objects won&rsquo;t work here.</em></p>

<p>As you can see above, the code invoking the <code>Email.to</code> method doesn&rsquo;t care about what it returns. In fact, it doesn&rsquo;t return anything we care about at this point. So as long as the method is called, the code can move forward without waiting for the email to finish sending.</p>

<p>Extracting asynchronous operations like this that exist in a code path is a
great way to improve performance. There are times, though, where deferring an operation to background job might not make sense.</p>

<p>For example, imagine a user changes the name of a person. They click one of their contact&rsquo;s names, enter a new name, and click &ldquo;Save&rdquo;. It doesn&rsquo;t make sense to send the task of updating the actual name in the database to a background job because depending on what else is in the queue at that time, the update might not complete until after the next refresh, which would make the user believe their update wasn&rsquo;t successful. This would be incredibly confusing.</p>

<p>Logging is another perfect candidate for asynchronicity. In most cases, our users don&rsquo;t care if a log of their actions has been written to the database before their next refresh. It&rsquo;s information we may want to store, and as a result, can be a fire-and-forget operation. We can rest easy knowing we&rsquo;ll have that information, soon-ish, and it won&rsquo;t add any additional overhead to the end user&rsquo;s request cycle.</p>

<p>The opposite of asynchronous events like this are <strong>synchronous</strong> events! (surprise right?). Let&rsquo;s explore how they&rsquo;re different.</p>

<h2>Synchronous Events</h2>

<p>We can look at synchronous events as dependencies of the request cycle. We use MySQL as a backend for the main PipelineDeals web application and queries to MySQL would be considered synchronous. In that, in order to successfully fulfill the current request, we require the information returned from MySQL before we can respond.</p>

<p>In most cases, we don&rsquo;t think of our main datastore as a service. It doesn&rsquo;t necessarily have a separate application layer on top of it, but it&rsquo;s behavior and requirements are very much like a service.</p>

<p>If we consider the addition of our billing service above, we require information about the features allowed for a particular account before we can render the page. This allows us to include/exclude modules they should or should not see. The flow goes something like this:</p>

<p><code>Web request -&gt; lookup account in DB -&gt; Request features from Billing service -&gt; render page</code></p>

<p>If the request to the billing service didn&rsquo;t require a response, we would consider this to be an <strong>asynchronous</strong> service, which might change how we invoke the request for data.</p>

<p>Synchronous communication can happen over a variety of protocols. The most
common is a JSON payload over HTTP. In general, it&rsquo;s not the most performant,
but it&rsquo;s one of the easier to debug and is human-readable, so it tends to be pretty popular.</p>

<p>The synchronous services we&rsquo;ve setup all communicate over HTTP. Rails APIs are a known thing. We&rsquo;re familiar with the stack and the dependencies required to set up a common JSON API, which is a large part of the reason it&rsquo;s our preferred communication protocol between services.</p>

<h2>Summary</h2>

<p>We&rsquo;ve simplified the communication between services into these two categories. Knowing this helps dictate the infrastructure and configuration of the applications.</p>

<p>Next time, we&rsquo;ll take a closer look at the synchronous side and the specifics about the JSON payloads involved to send an email successfully.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Path to Services - Part 1 - Start Small]]></title>
    <link href="http://brandonhilkert.com/blog/a-path-to-services-part-1-start-small/"/>
    <updated>2015-07-27T11:18:00-04:00</updated>
    <id>http://brandonhilkert.com/blog/a-path-to-services-part-1-start-small</id>
    <content type="html"><![CDATA[<p><em>This article was originally posted on the <a href="http://plumbing.pipelinedeals.com/">PipelineDeals Engineering
Blog</a></em></p>

<p>The PipelineDeals web application recently celebrated its ninth birthday. It&rsquo;s
seen its fair share of developers, all of whom had their own idea of &ldquo;clean
code&rdquo;. As a team, we&rsquo;d been brainstorming ways to wrangle certain areas of the
application. The question we&rsquo;d frequently ask ourselves was <em>&ldquo;How do we clean
up [x] (some neglected feature of the application)?</em>&rdquo;.</p>

<!--more-->


<p>Reasonable solutions ended up being:</p>

<ol>
<li>Rewrite it</li>
<li>Rewrite and put it elsewhere</li>
</ol>


<p>In short, we chose to rewrite many of the hairy areas of the app into separate services communicating over HTTP. It&rsquo;s been about a year since our first commit in a separate service, and we&rsquo;ve learned quite a bit since then. This is part 1 in a series of posts related to our transition to microservices.</p>

<h2>How we got here</h2>

<p>This was us 18 months ago. PipelineDeals was a crufty Rails 2 application that many of us were scared to open. It&rsquo;d been several years of adding feature upon feature without consistent knowledge, style, or guidance. And it&rsquo;s probably not surprising we had what we did. Regardless, we needed to fix it.</p>

<p>One of our goals was to move to Rails 3, and later more updated versions, but in order to get there, we had to refactor (or remove) quite a bit of code to make the transition easier.</p>

<p>This, to me, was a huge factor around our decision to move to a more service-focused approach. <a href="https://www.youtube.com/watch?v=KJVTM7mE1Cc">At this year&rsquo;s Railsconf keynote</a>, DHH joked about the &ldquo;majestic monolith&rdquo; and how many companies prematurely piece out services, all to later suffer pain when they realize it was a premature optimization.</p>

<p>The same could be said for our move. Instead of spinning out separate services, we could have cleaned up the mess we had by refactoring every nasty piece of our app. We could have turned our ugly monolith into a majestic one. But while it would&rsquo;ve been possible, our team agreed we were better served by more or less starting over. Not in the big-bang rewrite sense, but instead to stand up brand new service apps when we added new features, and when it made sense. &ldquo;Made sense&rdquo; is the key here. There have been many times when it didn&rsquo;t make sense over the past 12 months. But we&rsquo;re learning and getting better at identifying the things that are good candidates for a more isolated service.</p>

<h2>Now what?</h2>

<p><em>Do we wait for the next requested feature or what?</em></p>

<p>At one of our weekly team hangouts, we watched a talk focused on starting by isolating the responsibility of Email. It was the perfect introduction and motivation for us to get a small win and some experience under our belts. For some reason prior, we didn&rsquo;t have a great sense of how to start making that transition.</p>

<p>The idea was to take our emails (and there were plenty) and move them to a separate Rails app that&rsquo;s only responsibilty is sending email. While it sounds trivial, the idea alone introduces a lot of interesting questions: <em>What do we do with those really nasty emails that have 30 instance variables? What do we do if the email service is down? How do we trigger an email to be sent?</em></p>

<h2>Rails new</h2>

<p>We created a new Rails 4 app, removed all the stuff we didn&rsquo;t need and created a golden shrine where emails could flourish&hellip;but seriously, that&rsquo;s all it did. And it did it really well.</p>

<p>The next question was how to send emails from the main application. We&rsquo;re very happy <a href="http://sidekiq.org/pro/">Sidekiq Pro</a> users, and one of the benefits we love about Sidekiq is the built-in retries. This gives us a layer of reliability outside of the code layer. So rather than build some ad-hoc retry mechanism by creating a counter in ruby, and rescuing failures within a certain range, we shoot off a job. If it fails because the network is down, or the endpoint isn&rsquo;t available, the job will retry soon after and continue down the happy path. Sidekiq retries are a recurring theme with our infrastructure. We&rsquo;ve made a number of decisions around the fact that we have this advantage already built-in, and we might as well take advantage of it. More on that to come.</p>

<h2>Communicate</h2>

<p>The defacto communication method between services is over HTTP. And we did nothing different. Our services use JSON payloads to exchange data, which let&rsquo;s us easily take advantage of Sidekiq on both ends.</p>

<p>So now, rather than invoking a built-in Rails mailer like:</p>

<p><code>
UserMailer.welcome(current_user).deliver
</code></p>

<p>we invoke a PORO to send off the communication:</p>

<p><code>
Email.to current_user, :user_welcome
</code></p>

<p>where <code>Email</code> is defined as</p>

<p>```
class Email
  def initialize(users, email_key, opts)</p>

<pre><code>@users, @email_key, @opts = users, email_key, opts
</code></pre>

<p>  end</p>

<p>  def self.to(users, email_key, opts = {})</p>

<pre><code>new(users, email_key, opts).queue_email
</code></pre>

<p>  end</p>

<p>  def queue_email</p>

<pre><code>opts[:email_key] = email_key
opts[:to] ||= email_array
opts[:name] ||= first_users_name
opts[:user_id] ||= user_id
opts[:account_id] ||= account_id

json = JSON.generate(opts)
RestClient.post(ENV["PIPELINE_EMAIL_URL"], json, :content_type =&gt; :json)
</code></pre>

<p>  end
end
```</p>

<p>There&rsquo;re a number of use-case specific variables above, but the <code>email_key</code> is probably the most important. We used that to describe what email should be invoked on the service.</p>

<p>In the above example, we triggered the <code>welcome</code> email on the <code>UserMailer</code> class. We translated this request into an email key of <code>user_welcome</code>.</p>

<p>This key then gets interpreted by the Email service app and turned into an actual <code>Mailer</code> class and method within it. We could have done this in a variety of ways, but we split the string on the service-side at the <code>_</code>, and the first element described the mailer, the rest the method. So in this case, it gets interpreted as <code>UserMailer#welcome</code>.</p>

<p>One thing this pattern allowed us to do was almost full copy/paste the old mailer methods in to the new Email service application.</p>

<h2>Failures, failures, failures</h2>

<p>&ldquo;What if the service is down?&rdquo; you say, &ldquo;the email request will fail!&rdquo; Sure will.</p>

<p>So let&rsquo;s wrap that request in a Sidekiq job to take advantage of the built-in retries.</p>

<p>Rather than invoke the following method in the email object:</p>

<p><code>
RestClient.post(ENV["PIPELINE_EMAIL_URL"], json, :content_type =&gt; :json)
</code></p>

<p>we&rsquo;ll shoot off a Sidekiq job instead, changing the <code>queue_email</code> method to:</p>

<p>```
def queue_email
  opts[:email_key] = email_key
  opts[:to] ||= email_array
  opts[:name] ||= first_users_name
  opts[:user_id] ||= user_id
  opts[:account_id] ||= account_id</p>

<p>  EmailWorker.perform_async(opts)
end
```</p>

<p>There we have it. Network-proof email requests!</p>

<p>Not so fast&hellip;</p>

<p>Astute readers will probably recognize that the service-side network communication can potentially also fail. This is becoming a pattern, huh? More communication, more potential for failure and more potential headaches.</p>

<p>On the <strong>service side</strong>, we have a controller that takes in the request for the email and immediately serializes it to a Sidekiq job:</p>

<p>```
  def create</p>

<pre><code>EmailWorker.perform_async(parsed_params)
head :accepted
</code></pre>

<p>  end</p>

<p>  private</p>

<p>  def parse_params</p>

<pre><code>JSON.parse(request.body) || {}
</code></pre>

<p>  end
end
```</p>

<p>Because we immediately serialize the job to Sidekiq, we&rsquo;ve successfully acknowledged the job was received, and the main app&rsquo;s Sidekiq job completes successfully. Now the email service can move on to doing the heavy-lifting in whatever way makes the most sense. In our case, we use Mailgun to send our emails, so the <code>EmailWorker</code> Sidekiq job invokes a new mailer based on the <code>email_key</code> param and sends it off to mailgun for transport. And because it&rsquo;s wrapped in a Sidekiq job, we can sleep well knowing that the Mailgun request can fail and the job will successfully retry until it goes through.</p>

<h2>Summary</h2>

<p>Service communication is definitely not for the faint of heart and as a team, we can completely appreciate the challenges that come along with keeping services in sync now&mdash;especially having stood up about 8 new services in the last 12 months.</p>

<p>Sidekiq has been the queueing solution we&rsquo;ve leaned on to keep communication in sync and reliable. We&rsquo;ve also written a few internal tools that piggy-backy off Sidekiq that we&rsquo;re really excited share with the community in the near future.</p>

<p>Part II, in this series, will discuss the methods of communication necessary to consider when implementing a service-based architecture.</p>
]]></content>
  </entry>
  
</feed>

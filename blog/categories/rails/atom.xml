<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: rails | Brandon Hilkert]]></title>
  <link href="http://brandonhilkert.com/blog/categories/rails/atom.xml" rel="self"/>
  <link href="http://brandonhilkert.com/"/>
  <updated>2020-01-20T09:35:49-08:00</updated>
  <id>http://brandonhilkert.com/</id>
  <author>
    <name><![CDATA[Brandon Hilkert]]></name>
    <email><![CDATA[brandonhilkert@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Reducing Sidekiq Memory Usage with Jemalloc]]></title>
    <link href="http://brandonhilkert.com/blog/reducing-sidekiq-memory-usage-with-jemalloc/"/>
    <updated>2018-04-28T14:42:00-07:00</updated>
    <id>http://brandonhilkert.com/blog/reducing-sidekiq-memory-usage-with-jemalloc</id>
    <content type="html"><![CDATA[<p>Ruby and Rails don&rsquo;t have a reputation of being memory-friendly. This comes with a trade-off of being a higher level language that tends to be more developer-friendly. For me, it works. I&rsquo;m content knowing I might have to pay more to scale a large application knowing I can write it in a language I enjoy.</p>

<p>Turns out&hellip;Rubyâ€™s not the memory hog I&rsquo;d previously thought. After some research and experimentation, I&rsquo;ve found <code>jemalloc</code> to offer significant memory savings while at least preserving performance, if not improving it as well.</p>

<!--more-->


<h2>The Problem</h2>

<p>At <a href="https://www.bark.us">Bark</a>, we poll external APIs for millions of monitored social media, text, and emails. This is all done through <a href="http://sidekiq.org/">Sidekiq</a> background jobs. Even though Ruby doesn&rsquo;t truly allow parallelism, we see great benefit with Sidekiq concurrency as the jobs wait for external APIs to respond. The API responses can often be large, not to mention any media they might include. As a result, we see the memory usage of our Sidekiq workers increase until they&rsquo;re ultimately killed and restarted by <a href="https://www.freedesktop.org/wiki/Software/systemd/"><code>systemd</code></a>.</p>

<p>The following shows a common memory usage pattern for our queue servers:</p>

<p><img class="center" src="/images/jemalloc/sidekiq-memory-usage-before.png" title="&ldquo;Sidekiq servers memory usage before using jemalloc&rdquo;" ></p>

<p>Two things to notice:</p>

<ol>
<li><p><strong>Memory increased quickly</strong> &ndash; The rise of memory happens immediately after the processes are restarted. We deploy multiple times a day, but this was especially problematic on the weekends when deploys are happening less frequently</p></li>
<li><p><strong>Memory wasn&rsquo;t reused until restarted</strong> &ndash; The jaggedness of graph towards the center is the result of the memory limits we imposed on the <code>systemd</code> processes, causing them to be killed and ultimately restarted until they later reach the configured max memory setting again. Because the processes didn&rsquo;t appear to be reusing memory, we saw this happen just a few minutes after being restarted.</p></li>
</ol>


<h2>The Solution</h2>

<p>As the <a href="https://brandonhilkert.com/blog/why-i-wrote-the-sucker-punch-gem/">author of a multi-threaded background processing library</a>, I frequently see reports of memory leaks in Rails applications. As a Sidekiq user, <a href="https://github.com/mperham/sidekiq/issues/3824">this one caught my attention</a>. It starts as a classic memory leak report, but later turns towards deeper issues in the underlying operating system, not in the application. With <a href="https://www.speedshop.co/2017/12/04/malloc-doubles-ruby-memory.html">Nate Berkopec&rsquo;s post on Ruby memory usage in multi-threaded applications</a> referenced, the reporter found switching to <code>jemalloc</code> to fix their issue.</p>

<p><code>jemalloc</code> describes itself as:</p>

<blockquote><p>a general purpose malloc(3) implementation that emphasizes fragmentation avoidance and scalable concurrency support</p></blockquote>

<p>The description targets our use-case and issues with the current memory allocator. We were seeing terrible fragmentation when using Sidekiq (concurrent workers).</p>

<h3>How to use jemalloc</h3>

<p>Ruby can use <code>jemalloc</code> a few different ways. It can be compiled with <code>jemalloc</code>, but we already had Ruby installed and were interested in trying it with the least amount of infrastructure changes.</p>

<p>It turns out Ruby will attempt to use <code>jemalloc</code> if the <a href="https://github.com/jemalloc/jemalloc/wiki/Getting-Started">well-document environment variable <code>LD_PRELOAD</code></a> is set.</p>

<p>Our Sidekiq servers use Ubuntu 16.04, so we started by installing <code>jemalloc</code>:</p>

<p><figure class="code"><pre><code class="bash">sudo apt-get install libjemalloc-dev</code></pre></figure></p>

<p>From there, we configured the <code>LD_PRELOAD</code> environment variable by adding the following to <code>/etc/environment</code>:</p>

<p><figure class="code"><pre><code class="bash">LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libjemalloc.so.1</code></pre></figure></p>

<p><em>Note: The location of <code>jemalloc</code> may vary depending on version and/or Linux distribution.</em></p>

<h3>Benchmark</h3>

<p>We benchmarked <code>jemalloc</code> on just one of the queue servers. This would allow us to do a true comparison against similar activity.</p>

<p><img class="center" src="/images/jemalloc/sidekiq-memory-usage-comparison.png" title="&ldquo;Sidekiq server memory usage with one server using jemalloc&rdquo;" ></p>

<p>As we can see, the difference is drastic &mdash; <strong>over 4x decrease in memory usage</strong>!</p>

<p>The more impressive detail was the consistency. Total memory usage doesn&rsquo;t waver much. Processing large payloads and media, I assumed we&rsquo;d continue to see the peaks and valleys common to processing social media content. The sidekiq processes using <code>jemalloc</code> show a better ability to use previously allocated memory.</p>

<p><img class="center" src="/images/jemalloc/sidekiq-memory-usage-with-jemalloc-details.png" title="&ldquo;Sidekiq server memory usage details with one server using jemalloc&rdquo;" ></p>

<h3>Roll it in to production</h3>

<p>With similar behavior over a 3 day period, we concluded to roll it out to the remaining queue servers.</p>

<p>The reduced memory usage continues to be impressive, all without any noticeable negative trade-offs.</p>

<p><img class="center" src="/images/jemalloc/sidekiq-memory-usage-after.png" title="&ldquo;Sidekiq server memory usage after using jemalloc&rdquo;" ></p>

<h2>Conclusion</h2>

<p>We were surprised by the significant decrease in memory usage by switching to <code>jemalloc</code>. Based on the other reports, we assumed it be reasonable, but not a 4x decrease.</p>

<p>Even after looking at these graphs for the last couple days, the differences seem too good to be true. But all is well and it&rsquo;s hard to imagine NOT doing this for any Ruby server we deploy in the future.</p>

<p>Give it a shot. I&rsquo;d love to see your results.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Monitoring Sidekiq using AWS Lambda and CloudWatch]]></title>
    <link href="http://brandonhilkert.com/blog/monitoring-sidekiq-using-aws-lambda-and-cloudwatch/"/>
    <updated>2017-03-27T13:58:00-07:00</updated>
    <id>http://brandonhilkert.com/blog/monitoring-sidekiq-using-aws-lambda-and-cloudwatch</id>
    <content type="html"><![CDATA[<p>A few articles ago, I wrote about <a href="http://brandonhilkert.com/blog/monitoring-sidekiq-using-aws-lambda-and-slack/">how to monitor Sidekiq retries using AWS Lambda</a>. Retries are often the first indication of an issue if your application does a lot of background work.</p>

<p>As <a href="https://www.bark.us">Bark</a> continues to grow, we became interested in how the number of jobs enqueued and retrying trended over time. Using AWS Lambda to post this data to CloudWatch, we were able to visualize this data over time.</p>

<!--more-->


<h2>The Problem</h2>

<p><a href="http://sidekiq.org/">Sidekiq</a> offers a way to visual the jobs processed over time when on the dashboard. In fact, <a href="http://brandonhilkert.com/blog/3-ways-to-get-started-contributing-to-open-source/">this graph was one of my first open source contributions</a>.</p>

<p><img class="center" src="/images/sidekiq-cloudwatch/sidekiq-dashboard.png" title="&ldquo;Sidekiq Dashboard&rdquo;" ></p>

<p>Unfortunately, these graph don&rsquo;t show the number of retries from 2 am last night, or how long it took to exhaust the queues when 2 million jobs were created.</p>

<p>Historical queue data is important if our application does a lot of background work and number of users is growing. Seeing these performance characteristics over time can help us be more prepared to add more background workers or scale our infrastructure in a way to stay ahead when our application is growing quickly.</p>

<h2>The Solution</h2>

<p>Because Bark is on AWS, we naturally looked to their tools for assistance. We already use CloudWatch to store data about memory, disk, and CPU usage for each server. This has served us well and allows us to set alarms for certain thresholds and graph this data over time:</p>

<p><img class="center" src="/images/sidekiq-cloudwatch/cloudwatch-memory.png" title="&ldquo;Monitoring memory usage on AWS CloudWatch&rdquo;" ></p>

<p>Knowing we&rsquo;d have similar data for queue usage, we figured we could do the same with Sidekiq.</p>

<h3>Sidekiq Queue Data Endpoint</h3>

<p>If you remember from the last article on <a href="http://brandonhilkert.com/blog/monitoring-sidekiq-using-aws-lambda-and-slack/">monitoring Sidekiq retries using AWS Lambda</a>, we setup an endpoint in our application to return Sidekiq stats:</p>

<p>```
require &lsquo;sidekiq/api&rsquo;</p>

<p>class SidekiqQueuesController &lt; ApplicationController
  skip_before_action :require_authentication</p>

<p>  def index</p>

<pre><code>base_stats = Sidekiq::Stats.new
stats = {
   enqueued: base_stats.enqueued,
   queues: base_stats.queues,
   busy: Sidekiq::Workers.new.size,
   retries: base_stats.retry_size
}

render json: stats
</code></pre>

<p>  end
end
```</p>

<p>along with the route:</p>

<p><code>
resources :sidekiq_queues, only: [:index]
</code></p>

<p>Using this resource, we need to poll at some regular interval and store the results.</p>

<h3>AWS Lambda Function</h3>

<p>AWS Lambda functions are perfect for one-off functions that feel like a burden to maintain in our application.</p>

<p>For the trigger, we&rsquo;ll use &ldquo;CloudWatch Events &ndash; Schedule&rdquo;:</p>

<p><img class="center" src="/images/sidekiq-monitor/lambda-trigger.png" title="&ldquo;AWS Lambda trigger&rdquo;" ></p>

<p>From here, we&rsquo;ll enter a name and description for our rule and define its rate (I chose every 5 minutes). Enable the trigger and we&rsquo;ll move to defining our code. Next, we&rsquo;ll give the function a name and choose the latest NodeJS as the runtime. Within the inline editor, we&rsquo;ll use the following code:</p>

<p>```
var AWS = require(&lsquo;aws-sdk&rsquo;);
var url = require(&lsquo;url&rsquo;);
var https = require(&lsquo;https&rsquo;);</p>

<p>if (typeof Promise === &lsquo;undefined&rsquo;) {
  AWS.config.setPromisesDependency(require(&lsquo;bluebird&rsquo;));
}</p>

<p>var cloudwatch = new AWS.CloudWatch();</p>

<p>sidekiqUrl = &lsquo;[Sidekiq stat URL]&rsquo;</p>

<p>var logMetric = function(attr, value) {</p>

<pre><code>var params = {
    MetricData: [
        {
            MetricName: attr,
            Dimensions: [
                {
                    Name: "App",
                    Value: "www"
                }
            ],
            Timestamp: new Date(),
            Unit: "Count",
            Value: value
        }
    ],
    Namespace: "Queues"
};

return cloudwatch.putMetricData(params).promise();
</code></pre>

<p>}</p>

<p>var getQueueStats = function(statsUrl) {</p>

<pre><code>return new Promise(function(resolve, reject) {
    var options = url.parse(statsUrl);
    options.headers = {
        'Accept': 'application/json',
    };
    var req = https.request(options, function(res){
        var body = '';

        res.setEncoding('utf8');

        //another chunk of data has been recieved, so append it to `str`
        res.on('data', function (chunk) {
            body += chunk;
        });

        //the whole response has been recieved
        res.on('end', function () {
            resolve(JSON.parse(body));
        });
    });

    req.on('error', function(e) {
       reject(e);
    });

    req.end();
});
</code></pre>

<p>}</p>

<p>exports.handler = function(event, context) {</p>

<pre><code>getQueueStats(sidekiqUrl).then(function(stats) {
    console.log('STATS: ', stats);

    var retryPromise = logMetric("Retries", stats.retries);
    var busyPromise = logMetric("Busy", stats.busy);
    var enqueuedPromise = logMetric("Enqueued", stats.enqueued);

    Promise.all([retryPromise, busyPromise, enqueuedPromise]).then(function(values) {
        console.log(values);
        context.succeed();
    }).catch(function(err){
        console.error(err);
        context.fail("Server error when processing message: " + err );
    });
})
.catch(function(err) {
    console.error(err);
    context.fail("Failed to get stats from HTTP request: " + err );
});
</code></pre>

<p>};
```</p>

<p><em>Note: <code>sidekiqURL</code>  need to be defined with appropriate values for this to work.</em></p>

<p>Within CloudWatch, we&rsquo;re defining a new namespace (&ldquo;Queues&rdquo;) where our data will live. Within this namespace, we&rsquo;ll segregate these stats by the Dimension <code>App</code>. As we can see, we chose <code>www</code> for this value. If we wanted to monitor the queues of a few servers, each one could use a unique App name.</p>

<p>Review and save the Lambda function and we&rsquo;re all set!</p>

<h3>Graphing Sidekiq Queue Data</h3>

<p>Once the function has run a few times, under CloudWatch &mdash;> Metrics, we&rsquo;ll see the following custom namespace:</p>

<p><img class="center" src="/images/sidekiq-cloudwatch/custom-namespace.png" title="&ldquo;AWS CloudWatch Custom Namespace&rdquo;" ></p>

<p>From here, we&rsquo;ll choose the name of our app (<code>www</code>) and graph the values of each of these values over whatever timespan we want:</p>

<p><img class="center" src="/images/sidekiq-cloudwatch/sidekiq-queues.png" title="&ldquo;AWS CloudWatch Monitoring Sidekiq Queues&rdquo;" ></p>

<h2>Conclusion</h2>

<p>I&rsquo;ve found AWS lamba to be a great place for endpoints/functionality that feels cumbersome to include in my applications. Bringing deeper visibility to our Sidekiq queues has given us the ability to see usage trends we weren&rsquo;t aware of throughout the day. This will help us preemptively add infrastructure resources to keep up with our growth.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using PhantomJS to Capture Analytics for a Rails Email Template]]></title>
    <link href="http://brandonhilkert.com/blog/using-phantomjs-to-capture-analytics-for-a-rails-email-template/"/>
    <updated>2017-02-17T09:20:00-08:00</updated>
    <id>http://brandonhilkert.com/blog/using-phantomjs-to-capture-analytics-for-a-rails-email-template</id>
    <content type="html"><![CDATA[<p>Every Sunday <a href="https://www.bark.us">Bark</a> sends parents a weekly recap of their children&rsquo;s activity online. The first iteration was pretty basic, things like &ldquo;Your children sent X number of messages this past week&rdquo; and &ldquo;You have 10 messages to review&rdquo;. But we wanted to go deeper&hellip;</p>

<p>Using PhantomJS, we were able to take screenshots of a modified version of the application&rsquo;s child analytics page and include the image in the email sent to the parent. The email now contains everything the parent can see from the application, all without leaving their inbox.</p>

<!--more-->


<h2>The Problem</h2>

<p>If you&rsquo;ve every attempted to style an HTML email with anything more than text, you&rsquo;re sadly familiar with its limitations. Tables and other elements from the 90&rsquo;s are the only tools we have to maintain cross-platform compatibility. One of those tools, the subject of this post, is images.</p>

<p>Our weekly recap email contained a line chart illustrating the number of messages the child exchanged during the past week. While this was somewhat helpful to parents, it didn&rsquo;t tell the full story.</p>

<p><img class="center" src="/images/phantomjs/recap-v1.png" title="&ldquo;First version of the Bark weekly recap email&rdquo;" ></p>

<p>While this email does include a graph, it&rsquo;s the result of calling out to a service that rendered the graph, stored it, and returned the URL to include as an image. While this service worked well for simple illustrations, it didn&rsquo;t provide us the flexibility we had with modern web tools and visualizations. Aside from that, the styling of the charts is limited.</p>

<p>Elsewhere on Bark, we had already built the full story through other lists and illustrations.</p>

<p><img class="center" src="/images/phantomjs/analytics-interactions.png" title="&ldquo;Bark analytics with interactions&rdquo;" ></p>

<p><img class="center" src="/images/phantomjs/analytics-activities.png" title="&ldquo;Bark analytics with activities&rdquo;" ></p>

<p><img class="center" src="/images/phantomjs/analytics-time.png" title="&ldquo;Bark analytics over time&rdquo;" ></p>

<p>Recreating the same lists and charts just for the email felt like a duplication nightmare and vulnerable to becoming stale. We wouldn&rsquo;t be able to use the same rendering because most of the charts rendered SVGs, which aren&rsquo;t compatible with most email clients. Additionally, there were a handful of CSS styles needed for the page that while possible to include in the email, felt excessive.</p>

<p>Stepping back from the problem, we realized we wanted the majority of the analytics page, just embedded in the email. Was there a way to do that without rewriting it for email clients?</p>

<h2>The Solution</h2>

<p>We could take a screenshot of the analytics page and embed it as an image in the recap email.</p>

<h3>wkhtmltoimage</h3>

<p>Our first attempt was using <code>wkhtmltoimage</code> and the <a href="https://github.com/csquared/IMGKit"><code>IMGKit</code></a> ruby gem. Aside from the headaches of installing a working OSX version of <code>wkhtmltoimage</code> due to a regression, getting a working configuration was non-trivial.</p>

<p><code>wkhtmltoimage</code> doesn&rsquo;t parse CSS or JavaScript, so those would have to be explicitly included. Since Bark uses the asset pipeline, we&rsquo;d have to get the latest version of the compiled assets both on development and production. This proved to be extremely difficult under the default configuration given how each group is compiled. We use <a href="https://www.nginx.com/resources/wiki/">Nginx</a> to serve our assets in the production and it felt weird to have a configuration we would <em>hope</em> worked when we pushed to production.</p>

<p>After spending almost a full day trying to get the right combination of settings, we gave up. There had to be a better way&hellip;</p>

<h3>Saas FTW</h3>

<p>Frankly, our next step was to look for a Saas service that provided this functionality. Certainly I should be able to send a URL to an API, and they&rsquo;d return an image, perhaps with some configuration options for size and response. To our surprise, there were none (based on a 15 minute internet search. If you know of one, we&rsquo;d love to hear about it). There were plenty of services focused on rendering PDFs geared towards invoices and other documents one would want to email customers.</p>

<h3>PhantomJS</h3>

<p>We were reminded of Capybara&rsquo;s ability to capture screenshots on failed test runs. After poking around this functionality, <code>phantomjs</code> emerged as a potential solution.</p>

<p>If we installed <code>phantomjs</code> on to the server and ran a command line script to <a href="http://phantomjs.org/screen-capture.html">capture the screenshots</a> prior to sending the email, we could <a href="http://guides.rubyonrails.org/action_mailer_basics.html#complete-list-of-action-mailer-methods">inline include those images</a> in the email.</p>

<p>Installation of <code>phantomjs</code> was simplified using the <a href="https://github.com/colszowka/phantomjs-gem"><code>phantomjs-gem</code> ruby gem</a>, which installs the appropriate <code>phantomjs</code> binary for the operating system and provides an API (<code>#run</code>) to execute commands.</p>

<h3>Script the Screenshot</h3>

<p>Using a <a href="https://github.com/ariya/phantomjs/blob/master/examples/rasterize.js">screenshot example</a> from the <a href="https://github.com/ariya/phantomjs">PhantomJS github repo</a>, we put together a script (<code>vendor/assets/javascripts/phantom-screenshot.js</code>) to capture the analytics page:</p>

<p>```</p>

<h1>!/bin/sh</h1>

<p>var page   = require(&lsquo;webpage&rsquo;).create();
var system = require(&lsquo;system&rsquo;);
page.viewportSize = { width: 550, height: 600 };
page.zoomFactor = 0.85;</p>

<p>page.onError = function(msg, trace) {
  var msgStack = [&lsquo;ERROR: &rsquo; + msg];
  if (trace &amp;&amp; trace.length) {</p>

<pre><code>msgStack.push('TRACE:');
trace.forEach(function(t) {
  msgStack.push(' -&gt; ' + t.file + ': ' + t.line + (t.function ? ' (in function "' + t.function +'")' : ''));
});
</code></pre>

<p>  }</p>

<p>  console.error(msgStack.join(&lsquo;\n&rsquo;));
};</p>

<p>page.open(system.args[1], function(status) {
  if (status !== &lsquo;success&rsquo;) {</p>

<pre><code>console.log('Unable to load the address!');
phantom.exit(1);
</code></pre>

<p>  } else {</p>

<pre><code>window.setTimeout(function () {
  page.render(system.args[2]);
  phantom.exit();
}, 2000);
</code></pre>

<p>  }
});
<code>``
_Note: a variety of the settings (</code>viewPortSize<code>,</code>zoomFactor<code>, and</code>timeout`) were found using trial and error for our particular situation._</p>

<p>We use Sidekiq to enqueue the thousands of recap emails sent to parents each week. Because this approach relies on using our existing website as the source data for the screenshot, we have to be conscious of spreading the job processing over a certain period of time, so we don&rsquo;t overload the application for regular users.</p>

<h3>Create the Screenshot</h3>

<p>With this script in hand, now we can use the following class to create the image for each child:</p>

<p>```
class RecapAnalytics
  ScreenshotError = Class.new(StandardError)</p>

<p>  def initialize(analytics_url:)</p>

<pre><code>@analytics_url = analytics_url
</code></pre>

<p>  end</p>

<p>  def file_path</p>

<pre><code>unless create_screenshot
  raise ScreenshotError.new("Unable to complete analytics screenshot")
end

temp_file_path
</code></pre>

<p>  end</p>

<p>  def create_screenshot</p>

<pre><code>Phantomjs.run screenshot_script, analytics_url, temp_file_path
</code></pre>

<p>  end</p>

<p>  private</p>

<p>  attr_reader :analytics_url</p>

<p>  def screenshot_script</p>

<pre><code>Rails.root.join('vendor', 'assets', 'javascripts', 'phantom-screenshot.js').to_s
</code></pre>

<p>  end</p>

<p>  def temp_file_path</p>

<pre><code>@temp_file_path ||= begin
  file = Tempfile.new("child-analytics")
  file.path + ".png"
end
</code></pre>

<p>  end
end
```</p>

<p>For each child, we&rsquo;ll provide the URL to the child&rsquo;s analytics page and run the following <code>file_path</code> method to return the path of the screenshot:</p>

<p><code>
RecapAnalytics.new(analytics_url: "https://www.bark.us/children/XXX/analytics").file_path
</code></p>

<h2>Adding as an Inline Email Attachment</h2>

<p>With an image for each child, we can iterate through each child and inline include the image in the mailer:</p>

<p><code>
file_path = RecapAnalytics.new(analytics_url: "https://www.bark.us/children/XXX/analytics").file_path
attachments.inline["#{child.first_name}.png"] = File.read(file_path)
</code></p>

<p>Then in the email template, we can include the following to render the image:</p>

<p><code>erb
 &lt;%= link_to image_tag(attachments["#{child.first_name}.png"].url), child_url(child) %&gt;
</code></p>

<p><img class="center" src="/images/phantomjs/email-interactions.png" title="&ldquo;Bark weekly recap email with interactions&rdquo;" ></p>

<p><img class="center" src="/images/phantomjs/email-activities.png" title="&ldquo;Bark weekly recap email with activities&rdquo;" ></p>

<p><img class="center" src="/images/phantomjs/email-time.png" title="&ldquo;Bark weekly recap email over time&rdquo;" ></p>

<h2>Conclusion</h2>

<p>PhantomJS proved to be the simplest solution for the job. With a small script and no further configuration, we were able to lean on the analytics page we&rsquo;d already built to improve the Bark recap emails.</p>

<p>Parents will now have more visibility in to their child&rsquo;s online activity without leaving their inbox.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Monitoring Sidekiq Using AWS Lambda and Slack]]></title>
    <link href="http://brandonhilkert.com/blog/monitoring-sidekiq-using-aws-lambda-and-slack/"/>
    <updated>2016-10-25T11:54:00-07:00</updated>
    <id>http://brandonhilkert.com/blog/monitoring-sidekiq-using-aws-lambda-and-slack</id>
    <content type="html"><![CDATA[<p>It&rsquo;s no mystery I&rsquo;m a <a href="http://sidekiq.org/">Sidekiq</a> fan &mdash; my background job processing library of choice for any non-trivial applications. My favorite feature of Sidekiq has to be retries. By default, failed jobs will retry 25 times over the course of 21 days.</p>

<p>As a remote company, we use Slack to stay in touch with everyone AND to manage/monitor our infrastructure (hello #chatops). We can deploy from Slack (we don&rsquo;t generally, we have full CI) and be notified of infrastructure and application errors.</p>

<!--more-->


<p>When Sidekiq retries accumulate, it&rsquo;s a good indication that something more severe might be wrong. Rather than get an email we won&rsquo;t see for 30 minutes, we decided to integrate these notifications in to Slack. In doing so, we found <a href="https://aws.amazon.com/lambda/">AWS Lambda</a> to be a lightweight solution to tie the monitoring of Sidekiq and notifications in Slack together.</p>

<h2>The Problem</h2>

<p><a href="https://www.bark.us/">Bark</a> is background job-heavy. The web application is a glorified CRUD app that sets up the data needed to poll a child&rsquo;s social media feed and monitor for potential issues. The best-case scenario for a parent is that they will never hear from us.</p>

<p>Because Bark&rsquo;s background jobs commonly interact with 3rd-party APIs, failures aren&rsquo;t a big surprise. APIs can be down, network connections can fail &mdash; Sidekiq&rsquo;s retry logic protects us from transient network errors. Under normal circumstances, jobs retry and ultimately run successfully after subsequent attempts. These are non-issues and something we don&rsquo;t need an engineer to investigate.</p>

<p>There are times when retries accumulate, giving us a strong indication that something more severe may be wrong. Initially, we setup New Relic to notify us of an increased error rate. This worked for simple cases, but was sometimes a false positive. As a result, we started to ignore them, which potentially masked more important issues.</p>

<p>We soon realized one of the gauges of application health was the number of retries in the Sidekiq queue. We have the Sidekiq Web UI mounted within our admin application, so we&rsquo;d browse there a few times a day to make sure the number of retries weren&rsquo;t outside our expectations (in this case &lt; 50 were acceptable).</p>

<p>This wasn&rsquo;t a great use of our time. Ideally, we wanted a Slack notification when the number of Sidekiq retries was > 50.</p>

<h2>The Solution</h2>

<p>Because Bark is on AWS, we naturally looked to their tools for assistance. In this case, we needed something that would poll Sidekiq, check the number of retries, and <code>POST</code> to Slack if the number of retries was > 50.</p>

<p>There were a few options:</p>

<ol>
<li>Add the Sidekiq polling and Slack notification logic to our main application and setup a Cron job</li>
<li>Create a new satellite application that ONLY does the above (microservices???)</li>
<li>Setup an AWS Lambda function to handle the above logic</li>
</ol>


<p>The first two options would&rsquo;ve worked, but I was hesistant to add complexity to our main application. I was also hesitant to have to manage another application (ie. updates, etc.) for something that seemed simple.</p>

<p>Option &ldquo;AWS Lambda&rdquo; won! Let&rsquo;s take a look at the implementation.</p>

<h3>Sidekiq Queue Data Endpoint</h3>

<p>First, we need to expose the number of Sideki retries somehow. As I mentioned above, the Sidekiq web UI is mounted in our admin application, but behind an authentication layer that would&rsquo;ve been non-trivial to publicly expose.</p>

<p>Instead, we created a new Rails route to respond with some basic details about the Sidekiq system.</p>

<p>```
require &lsquo;sidekiq/api&rsquo;</p>

<p>class SidekiqQueuesController &lt; ApplicationController
  skip_before_action :require_authentication</p>

<p>  def index</p>

<pre><code>base_stats = Sidekiq::Stats.new
stats = {
   enqueued: base_stats.enqueued,
   queues: base_stats.queues,
   busy: Sidekiq::Workers.new.size,
   retries: base_stats.retry_size
}

render json: stats
</code></pre>

<p>  end
end
```</p>

<p>along with the route:</p>

<p><code>
resources :sidekiq_queues, only: [:index]
</code></p>

<p>As you can see, the endpoint is public (there&rsquo;s no job args or names exposed &mdash; just counts). The code digs in to the <a href="https://github.com/mperham/sidekiq/wiki/API">Sidekiq API</a> to interrogate the size of queues.</p>

<h3>Slack Incoming WebHook</h3>

<p>We want to be able to POST to Slack when the number of Sidekiq retries are > 50. To do this, we&rsquo;ll setup a custom incoming webhook integration in Slack.</p>

<p>We&rsquo;ll start by choose <code>Apps &amp; integrations</code> from within the main Slack options. From here, choose <code>Manage</code> in the top right, and then <code>Custom Integrations</code> on the left. You&rsquo;ll have 2 options:</p>

<ol>
<li>Incoming WebHooks</li>
<li>Slash Commands</li>
</ol>


<p>We&rsquo;ll choose <code>Incoming Webhooks</code> and choose <code>Add Configuration</code> to add a new one. From here, we&rsquo;ll supply the information needed to specify the channel where the notifications will appear and how they look.</p>

<p>The most important of this step is to get the <code>Webhook URL</code>. This will be the URL we <code>POST</code> to from within our Lambda function when retries are above our acceptable threshold.</p>

<h3>AWS Lambda Function</h3>

<p>Now that we have our endpoint to expose the number of retries (among other things) and the Slack webhook URL to <code>POST</code> to, we need to setup the AWS Lambda function to tie to the two together. We&rsquo;ll start by creating a new Lambda function with the defaults &mdash; using the latest Node.</p>

<p>For the trigger, we&rsquo;ll use &ldquo;CloudWatch Events &ndash; Schedule&rdquo;:</p>

<p><img class="center" src="/images/sidekiq-monitor/lambda-trigger.png" title="&ldquo;AWS Lambda trigger&rdquo;" ></p>

<p>From here, we&rsquo;ll enter a name and description for our rule and define its rate (I chose every 5 minutes). Enable the trigger and we&rsquo;ll move to defining our code. Next, we&rsquo;ll give the function a name and choose the latest NodeJS as the runtime. Within the inline editor, we&rsquo;ll use the following code:</p>

<p>```
var AWS = require(&lsquo;aws-sdk&rsquo;);
var url = require(&lsquo;url&rsquo;);
var https = require(&lsquo;https&rsquo;);
var sidekiqURL, hookUrl, slackChannel, retryThreshold;</p>

<p>sidekiqUrl = &lsquo;[Sidekiq queue JSON endpoint]&rsquo;
hookUrl = &lsquo;[Slack Incoming WebHooks URL w/ token]&rsquo;;
slackChannel = &lsquo;#operations&rsquo;;  // Enter the Slack channel to send a message to
retryThreshold = 50;</p>

<p>var postMessageToSlack = function(message, callback) {</p>

<pre><code>var body = JSON.stringify(message);
var options = url.parse(hookUrl);
options.method = 'POST';
options.headers = {
    'Content-Type': 'application/json',
    'Content-Length': Buffer.byteLength(body),
};

var postReq = https.request(options, function(res) {
    var chunks = [];
    res.setEncoding('utf8');
    res.on('data', function(chunk) {
        return chunks.push(chunk);
    });
    res.on('end', function() {
        var body = chunks.join('');
        if (callback) {
            callback({
                body: body,
                statusCode: res.statusCode,
                statusMessage: res.statusMessage
            });
        }
    });
    return res;
});

postReq.write(body);
postReq.end();
</code></pre>

<p>};</p>

<p>var getQueueStats = function(callback) {</p>

<pre><code>var options = url.parse(sidekiqUrl);
options.headers = {
    'Accept': 'application/json',
};

var getReq = https.request(options, function(res){
    var body = '';

    res.setEncoding('utf8');

    //another chunk of data has been recieved, so append it to `str`
    res.on('data', function (chunk) {
        body += chunk;
    });

    //the whole response has been recieved, so we just print it out here
    res.on('end', function () {
        if (callback) {
            callback({
                body: JSON.parse(body),
                statusCode: res.statusCode,
                statusMessage: res.statusMessage
            });
        }
    });
})

getReq.end();
</code></pre>

<p>}</p>

<p>var processEvent = function(event, context) {</p>

<pre><code>getQueueStats(function(stats){
    console.log('STATS: ', stats.body);

    var retries = stats.body.retries;

    if (retries &gt; retryThreshold) {
        var slackMessage = {
            channel: slackChannel,
            text: "www Sidekiq retries - " + retries
        };

        postMessageToSlack(slackMessage, function(response) {
            if (response.statusCode &lt; 400) {
                console.info('Message posted successfully');
                context.succeed();
            } else if (response.statusCode &lt; 500) {
                console.error("Error posting message to Slack API: " + response.statusCode + " - " + response.statusMessage);
                context.succeed();  // Don't retry because the error is due to a problem with the request
            } else {
                // Let Lambda retry
                context.fail("Server error when processing message: " + response.statusCode + " - " + response.statusMessage);
            }
        });
    } else {
        console.info('Sidekiq retries were ' + retries + ' . Below threshold.');
        context.succeed();
    }
})
</code></pre>

<p>};</p>

<p>exports.handler = function(event, context) {</p>

<pre><code>processEvent(event, context);
</code></pre>

<p>};
```</p>

<p><em>Note: <code>sidekiqURL</code> and <code>hookURL</code> need to be defined with appropriate values for this to work.</em></p>

<p>Review and save the Lambda function and we&rsquo;re all set!</p>

<h3>Review</h3>

<p>We can review the Lambda function logs on CloudWatch. Go to CloudWatch and choose &ldquo;Logs&rdquo; from the left menu. From here, we&rsquo;ll click the link to the name of our Lambda function:</p>

<p><img class="center" src="/images/sidekiq-monitor/sidekiq-logs.png" title="&ldquo;AWS Cloudwatch logs&rdquo;" ></p>

<p>From here, logs for each invocation of the Lambda function will be grouped in to a log stream:</p>

<p><img class="center" src="/images/sidekiq-monitor/log-streams.png" title="&ldquo;AWS Cloudwatch log streams&rdquo;" ></p>

<p>Grouped by time, each link will contain multiple invocations. A single execution is wrapped with a <code>START</code> and <code>END</code>, as shown in the logs. Messages in between will be calls to <code>console.log</code> from within our function. We logged the results of the Sidekiq queue poll for debugging purposes, so you can see that below:</p>

<p><img class="center" src="/images/sidekiq-monitor/log.png" title="&ldquo;AWS Cloudwatch log&rdquo;" ></p>

<p>This was invocation where the number of retries were &lt; 50, and a result, didn&rsquo;t need to <code>POST</code> to Slack. Let&rsquo;s take a look at the opposite:</p>

<p><img class="center" src="/images/sidekiq-monitor/log-post.png" title="&ldquo;AWS Cloudwatch log posting to Slack&rdquo;" ></p>

<p>We can see the <code>Message posted successfully</code> log indicating our message was successfully sent to Slack&rsquo;s incoming webhook.</p>

<p>Finally, here&rsquo;s what the resulting message looks like in Slack when the number of Sidekiq retries are above our threshold:</p>

<p><img class="center" src="/images/sidekiq-monitor/slack.png" title="&ldquo;Slack notifications for Sidekiq retries&rdquo;" ></p>

<h2>Conclusion</h2>

<p>Using new tools is fun, but not when it brings operational complexity. I&rsquo;ve personally found AWS lamba to be a great place for endpoints/functionality that feels cumbersome to include in my applications. Bringing these notifications in to Slack has been a big win for our team. We took a previously untrustworthy notification (NewRelic error rate) and brought some clarity to the state and health of our applications.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rails Progress Indicator for Turbolinks Using Nprogress]]></title>
    <link href="http://brandonhilkert.com/blog/rails-progress-indicator-for-turbolinks-using-nprogress/"/>
    <updated>2016-04-29T09:44:00-07:00</updated>
    <id>http://brandonhilkert.com/blog/rails-progress-indicator-for-turbolinks-using-nprogress</id>
    <content type="html"><![CDATA[<p>Contrary to popular opinion, I&rsquo;m a fan of <a href="https://github.com/turbolinks/turbolinks">Turbolinks</a>.
I leave it enabled in all my Rails applications. Most of the negative opinions I hear relate to it &ldquo;breaking&rdquo; third-party jQuery plugins. I say &ldquo;breaking&rdquo; because it&rsquo;s not <em>really</em> changing the plugin&rsquo;s behavior &mdash; just requires the plugin to be initialized differently.</p>

<!--more-->


<p>If you&rsquo;re upgrading to a newer version of Rails and have a bunch of legacy JavaScript code, I can imagine this being difficult. But if you&rsquo;re green-fielding a new application, there&rsquo;s no reason not to take advantage of it. I wrote extensively about <a href="http://brandonhilkert.com/blog/organizing-javascript-in-rails-application-with-turbolinks/">how to organize JavaScript in a Rails application with Turbolinks enabled</a>. If you&rsquo;re struggling to get your JavaScript code to work as expected on clicks through the application, take a look at that post. I continue to use that organization pattern for all my applications and it never lets me down.</p>

<p>With Turbolinks enabled, interacting with an application feels smooth and fast. No more full page refreshes.</p>

<p>Every once in awhile we&rsquo;ll stumble on a page request takes longer than others. Rather than having the user sit there thinking nothing is happening, we can offer better feedback through a loading progress bar, specifically <a href="http://ricostacruz.com/nprogress/">nprogress</a>. I&rsquo;ve found it to be the perfect companion to Turbolinks to create a great user experience.</p>

<h2>The Problem</h2>

<p>In a traditional web application, when we click a link or submit a form, we get a loading spinner where the favicon typically appears. We might also see text in the status bar saying &ldquo;Connecting&hellip;&rdquo; or &ldquo;Loading&hellip;&rdquo;. These are the loading indications that internet users have become accustomed to.</p>

<p>By adopting Turbolinks, we not longer get those loading feedback mechanisms because the request for the new page is asynchronous. Once the request is complete, the new content is rendered in place of the previous page&rsquo;s body element. For fast page loads, this isn&rsquo;t a problem. However, if you have applications like mine, every once in awhile, you might have a page request take a few seconds (reasons for this are beyond the scope of this article). In those cases, a user might click a link and sit there for 2-3 sec. without any indication the page is loading. While Turbolinks generally improves the user experience of our application, having no user feedback for several seconds is not ideal (ideally, you&rsquo;d want to address a page request that takes multiple seconds). This is where <code>nprogress</code> can help.</p>

<h2>The Solution</h2>

<p><a href="http://ricostacruz.com/nprogress/"><code>nprogress</code></a> is a progress loading indicator, like what you see on YouTube.</p>

<p>Like other JavaScript libraries, there&rsquo;s <a href="https://github.com/caarlos0/nprogress-rails">a Ruby Gem that vendors the code and includes it in the Rails asset pipeline</a>.</p>

<p>We&rsquo;ll first add <code>nprogress-rails</code> to our Gemfile:</p>

<p><code>
gem "nprogress-rails"
</code></p>

<p>Bundle to install the new gem:</p>

<p><code>
$ bundle install
</code></p>

<p>Now with <code>nprogress</code> installed, we need to include the JavaScript in our application. We&rsquo;ll do this by adding the following the <code>app/assets/javascripts/application.js</code> manifest:</p>

<p><code>
//= require nprogress
//= require nprogress-turbolinks
</code></p>

<p>We first include the <code>nprogress</code> JavaScript source, and then an adapter that&rsquo;ll hook the Turbolinks request to the progress indicator.</p>

<p><em>Note: If you&rsquo;re familiar with Turbolinks and its events, you&rsquo;ll recognize the <a href="https://github.com/caarlos0/nprogress-rails/blob/master/app/assets/javascripts/nprogress-turbolinks.js">events triggered</a>.</em></p>

<p>By default, the <code>nprogress</code> loading bar is anchored to the top of the browser window, but we need to include some CSS to make this work. Let&rsquo;s open the <code>app/assets/stylesheets/application.scss</code> manifest file and add the following:</p>

<p><code>
*= require nprogress
*= require nprogress-bootstrap
</code></p>

<p><em>Note: Including <code>nprogress-bootstrap</code> isn&rsquo;t necessary if you don&rsquo;t use <a href="http://getbootstrap.com/css/">Bootstrap</a> in your application. I typically do, so I&rsquo;m going to include it.</em></p>

<p>At this point, we&rsquo;ll have a working loading indicator. But what if we want to tweak the styles to match your application&rsquo;s theme?</p>

<h2>Customizing Nprogress Styles</h2>

<p>Because the <a href="https://github.com/caarlos0/nprogress-rails/blob/master/app/assets/stylesheets/nprogress.scss#L1"><code>nprgress</code> styles are Sass</a>, we can overwrite the variables for customization.</p>

<p>There are 3 variables available to overwite:</p>

<ul>
<li><code>$nprogress-color</code></li>
<li><code>$nprogress-height</code></li>
<li><code>$nprogress-zindex</code></li>
</ul>


<p>For <a href="https://www.bark.us/">Bark</a>, we have an aqua accent color with use throughout the site. It made sense for the <code>nprogress</code> loading indicator to be that same color.</p>

<p>Back in our <code>app/assets/stylesheets/application.scss</code>, I overwrote the variable before including the <code>nprogress</code> source code:</p>

<p>```
$nprogress-color: #37c8c9;</p>

<p>@import &ldquo;nprogress&rdquo;;
@import &ldquo;nprogress-bootstrap&rdquo;;
```</p>

<h2>Summary</h2>

<p>I&rsquo;ve found <code>nprogress</code> to be a great companion library to Turbolinks. The two libraries together provide a much better user experience over full page refreshes. Turbolinks helps asynchronously load the page content that&rsquo;s changing and <code>nprogress</code> gives the user feedback that their request is in progress. Now, even when a user has to suffer through multi-second page loads, at least they&rsquo;ll know it&rsquo;s not broken and don&rsquo;t have to click again.</p>

<p>The <a href="https://github.com/turbolinks/turbolinks/blob/master/src/turbolinks/progress_bar.coffee">latest version of Turbolinks has a progress bar
built-in</a>.
I&rsquo;m looking forward to removing the dependency if it performs similarly.</p>
]]></content>
  </entry>
  
</feed>

<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: sidekiq | Brandon Hilkert]]></title>
  <link href="http://brandonhilkert.com/blog/categories/sidekiq/atom.xml" rel="self"/>
  <link href="http://brandonhilkert.com/"/>
  <updated>2016-11-16T07:59:38-05:00</updated>
  <id>http://brandonhilkert.com/</id>
  <author>
    <name><![CDATA[Brandon Hilkert]]></name>
    <email><![CDATA[brandonhilkert@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Monitoring Sidekiq Using AWS Lambda and Slack]]></title>
    <link href="http://brandonhilkert.com/blog/monitoring-sidekiq-using-aws-lambda-and-slack/"/>
    <updated>2016-10-25T11:54:00-04:00</updated>
    <id>http://brandonhilkert.com/blog/monitoring-sidekiq-using-aws-lambda-and-slack</id>
    <content type="html"><![CDATA[<p>It&rsquo;s no mystery I&rsquo;m a <a href="http://sidekiq.org/">Sidekiq</a> fan &mdash; my background job processing library of choice for any non-trivial applications. My favorite feature of Sidekiq has to be retries. By default, failed jobs will retry 25 times over the course of 21 days.</p>

<p>As a remote company, we use Slack to stay in touch with everyone AND to manage/monitor our infrastructure (hello #chatops). We can deploy from Slack (we don&rsquo;t generally, we have full CI) and be notified of infrastructure and application errors.</p>

<!--more-->


<p>When Sidekiq retries accumulate, it&rsquo;s a good indication that something more severe might be wrong. Rather than get an email we won&rsquo;t see for 30 minutes, we decided to integrate these notifications in to Slack. In doing so, we found <a href="https://aws.amazon.com/lambda/">AWS Lambda</a> to be a lightweight solution to tie the monitoring of Sidekiq and notifications in Slack together.</p>

<h2>The Problem</h2>

<p><a href="https://www.bark.us/">Bark</a> is background job-heavy. The web application is a glorified CRUD app that sets up the data needed to poll a child&rsquo;s social media feed and monitor for potential issues. The best-case scenario for a parent is that they will never hear from us.</p>

<p>Because Bark&rsquo;s background jobs commonly interact with 3rd-party APIs, failures aren&rsquo;t a big surprise. APIs can be down, network connections can fail &mdash; Sidekiq&rsquo;s retry logic protects us from transient network errors. Under normal circumstances, jobs retry and ultimately run successfully after subsequent attempts. These are non-issues and something we don&rsquo;t need an engineer to investigate.</p>

<p>There are times when retries accumulate, giving us a strong indication that something more severe may be wrong. Initially, we setup New Relic to notify us of an increased error rate. This worked for simple cases, but was sometimes a false positive. As a result, we started to ignore them, which potentially masked more important issues.</p>

<p>We soon realized one of the gauges of application health was the number of retries in the Sidekiq queue. We have the Sidekiq Web UI mounted within our admin application, so we&rsquo;d browse there a few times a day to make sure the number of retries weren&rsquo;t outside our expectations (in this case &lt; 50 were acceptable).</p>

<p>This wasn&rsquo;t a great use of our time. Ideally, we wanted a Slack notification when the number of Sidekiq retries was > 50.</p>

<h2>The Solution</h2>

<p>Because Bark is on AWS, we naturally looked to their tools for assistance. In this case, we needed something that would poll Sidekiq, check the number of retries, and <code>POST</code> to Slack if the number of retries was > 50.</p>

<p>There were a few options:</p>

<ol>
<li>Add the Sidekiq polling and Slack notification logic to our main application and setup a Cron job</li>
<li>Create a new satellite application that ONLY does the above (microservices???)</li>
<li>Setup an AWS Lambda function to handle the above logic</li>
</ol>


<p>The first two options would&rsquo;ve worked, but I was hesistant to add complexity to our main application. I was also hesitant to have to manage another application (ie. updates, etc.) for something that seemed simple.</p>

<p>Option &ldquo;AWS Lambda&rdquo; won! Let&rsquo;s take a look at the implementation.</p>

<h3>Sidekiq Queue Data Endpoint</h3>

<p>First, we need to expose the number of Sideki retries somehow. As I mentioned above, the Sidekiq web UI is mounted in our admin application, but behind an authentication layer that would&rsquo;ve been non-trivial to publicly expose.</p>

<p>Instead, we created a new Rails route to respond with some basic details about the Sidekiq system.</p>

<p>```
require &lsquo;sidekiq/api&rsquo;</p>

<p>class SidekiqQueuesController &lt; ApplicationController
  skip_before_action :require_authentication</p>

<p>  def index</p>

<pre><code>base_stats = Sidekiq::Stats.new
stats = {
   enqueued: base_stats.enqueued,
   queues: base_stats.queues,
   busy: Sidekiq::Workers.new.size,
   retries: base_stats.retry_size
}

render json: stats
</code></pre>

<p>  end
end
```</p>

<p>along with the route:</p>

<p><code>
resources :sidekiq_queues, only: [:index]
</code></p>

<p>As you can see, the endpoint is public (there&rsquo;s no job args or names exposed &mdash; just counts). The code digs in to the <a href="https://github.com/mperham/sidekiq/wiki/API">Sidekiq API</a> to interrogate the size of queues.</p>

<h3>Slack Incoming WebHook</h3>

<p>We want to be able to POST to Slack when the number of Sidekiq retries are > 50. To do this, we&rsquo;ll setup a custom incoming webhook integration in Slack.</p>

<p>We&rsquo;ll start by choose <code>Apps &amp; integrations</code> from within the main Slack options. From here, choose <code>Manage</code> in the top right, and then <code>Custom Integrations</code> on the left. You&rsquo;ll have 2 options:</p>

<ol>
<li>Incoming WebHooks</li>
<li>Slash Commands</li>
</ol>


<p>We&rsquo;ll choose <code>Incoming Webhooks</code> and choose <code>Add Configuration</code> to add a new one. From here, we&rsquo;ll supply the information needed to specify the channel where the notifications will appear and how they look.</p>

<p>The most important of this step is to get the <code>Webhook URL</code>. This will be the URL we <code>POST</code> to from within our Lambda function when retries are above our acceptable threshold.</p>

<h3>AWS Lambda Function</h3>

<p>Now that we have our endpoint to expose the number of retries (among other things) and the Slack webhook URL to <code>POST</code> to, we need to setup the AWS Lambda function to tie to the two together. We&rsquo;ll start by creating a new Lambda function with the defaults &mdash; using the latest Node.</p>

<p>For the trigger, we&rsquo;ll use &ldquo;CloudWatch Events &ndash; Schedule&rdquo;:</p>

<p><img class="center" src="/images/sidekiq-monitor/lambda-trigger.png" title="&ldquo;AWS Lambda trigger&rdquo;" ></p>

<p>From here, we&rsquo;ll enter a name and description for our rule and define its rate (I chose every 5 minutes). Enable the trigger and we&rsquo;ll move to defining our code. Next, we&rsquo;ll give the function a name and choose the latest NodeJS as the runtime. Within the inline editor, we&rsquo;ll use the following code:</p>

<p>```
var AWS = require(&lsquo;aws-sdk&rsquo;);
var url = require(&lsquo;url&rsquo;);
var https = require(&lsquo;https&rsquo;);
var sidekiqURL, hookUrl, slackChannel, retryThreshold;</p>

<p>sidekiqUrl = &lsquo;[Sidekiq queue JSON endpoint]&rsquo;
hookUrl = &lsquo;[Slack Incoming WebHooks URL w/ token]&rsquo;;
slackChannel = &lsquo;#operations&rsquo;;  // Enter the Slack channel to send a message to
retryThreshold = 50;</p>

<p>var postMessageToSlack = function(message, callback) {</p>

<pre><code>var body = JSON.stringify(message);
var options = url.parse(hookUrl);
options.method = 'POST';
options.headers = {
    'Content-Type': 'application/json',
    'Content-Length': Buffer.byteLength(body),
};

var postReq = https.request(options, function(res) {
    var chunks = [];
    res.setEncoding('utf8');
    res.on('data', function(chunk) {
        return chunks.push(chunk);
    });
    res.on('end', function() {
        var body = chunks.join('');
        if (callback) {
            callback({
                body: body,
                statusCode: res.statusCode,
                statusMessage: res.statusMessage
            });
        }
    });
    return res;
});

postReq.write(body);
postReq.end();
</code></pre>

<p>};</p>

<p>var getQueueStats = function(callback) {</p>

<pre><code>var options = url.parse(sidekiqUrl);
options.headers = {
    'Accept': 'application/json',
};

var getReq = https.request(options, function(res){
    var body = '';

    res.setEncoding('utf8');

    //another chunk of data has been recieved, so append it to `str`
    res.on('data', function (chunk) {
        body += chunk;
    });

    //the whole response has been recieved, so we just print it out here
    res.on('end', function () {
        if (callback) {
            callback({
                body: JSON.parse(body),
                statusCode: res.statusCode,
                statusMessage: res.statusMessage
            });
        }
    });
})

getReq.end();
</code></pre>

<p>}</p>

<p>var processEvent = function(event, context) {</p>

<pre><code>getQueueStats(function(stats){
    console.log('STATS: ', stats.body);

    var retries = stats.body.retries;

    if (retries &gt; retryThreshold) {
        var slackMessage = {
            channel: slackChannel,
            text: "www Sidekiq retries - " + retries
        };

        postMessageToSlack(slackMessage, function(response) {
            if (response.statusCode &lt; 400) {
                console.info('Message posted successfully');
                context.succeed();
            } else if (response.statusCode &lt; 500) {
                console.error("Error posting message to Slack API: " + response.statusCode + " - " + response.statusMessage);
                context.succeed();  // Don't retry because the error is due to a problem with the request
            } else {
                // Let Lambda retry
                context.fail("Server error when processing message: " + response.statusCode + " - " + response.statusMessage);
            }
        });
    } else {
        console.info('Sidekiq retries were ' + retries + ' . Below threshold.');
        context.succeed();
    }
})
</code></pre>

<p>};</p>

<p>exports.handler = function(event, context) {</p>

<pre><code>processEvent(event, context);
</code></pre>

<p>};
```</p>

<p><em>Note: <code>sidekiqURL</code> and <code>hookURL</code> need to be defined with appropriate values for this to work.</em></p>

<p>Review and save the Lambda function and we&rsquo;re all set!</p>

<h3>Review</h3>

<p>We can review the Lambda function logs on CloudWatch. Go to CloudWatch and choose &ldquo;Logs&rdquo; from the left menu. From here, we&rsquo;ll click the link to the name of our Lambda function:</p>

<p><img class="center" src="/images/sidekiq-monitor/sidekiq-logs.png" title="&ldquo;AWS Cloudwatch logs&rdquo;" ></p>

<p>From here, logs for each invocation of the Lambda function will be grouped in to a log stream:</p>

<p><img class="center" src="/images/sidekiq-monitor/log-streams.png" title="&ldquo;AWS Cloudwatch log streams&rdquo;" ></p>

<p>Grouped by time, each link will contain multiple invocations. A single execution is wrapped with a <code>START</code> and <code>END</code>, as shown in the logs. Messages in between will be calls to <code>console.log</code> from within our function. We logged the results of the Sidekiq queue poll for debugging purposes, so you can see that below:</p>

<p><img class="center" src="/images/sidekiq-monitor/log.png" title="&ldquo;AWS Cloudwatch log&rdquo;" ></p>

<p>This was invocation where the number of retries were &lt; 50, and a result, didn&rsquo;t need to <code>POST</code> to Slack. Let&rsquo;s take a look at the opposite:</p>

<p><img class="center" src="/images/sidekiq-monitor/log-post.png" title="&ldquo;AWS Cloudwatch log posting to Slack&rdquo;" ></p>

<p>We can see the <code>Message posted successfully</code> log indicating our message was successfully sent to Slack&rsquo;s incoming webhook.</p>

<p>Finally, here&rsquo;s what the resulting message looks like in Slack when the number of Sidekiq retries are above our threshold:</p>

<p><img class="center" src="/images/sidekiq-monitor/slack.png" title="&ldquo;Slack notifications for Sidekiq retries&rdquo;" ></p>

<h2>Conclusion</h2>

<p>Using new tools is fun, but not when it brings operational complexity. I&rsquo;ve personally found AWS lamba to be a great place for endpoints/functionality that feels cumbersome to include in my applications. Bringing these notifications in to Slack has been a big win for our team. We took a previously untrustworthy notification (NewRelic error rate) and brought some clarity to the state and health of our applications.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Lessons Learned from Building a Ruby Gem API]]></title>
    <link href="http://brandonhilkert.com/blog/lessons-learned-from-building-a-ruby-gem-api/"/>
    <updated>2016-01-04T13:12:00-05:00</updated>
    <id>http://brandonhilkert.com/blog/lessons-learned-from-building-a-ruby-gem-api</id>
    <content type="html"><![CDATA[<p>Sucker Punch was created because I had a <a href="http://brandonhilkert.com/blog/why-i-wrote-the-sucker-punch-gem/">need for background processing without a separate worker</a>. But I also figured others did too, given that adding a worker dyno on Heroku was $35. For hobby apps, this was a significant cost.</p>

<p>Having gotten familiar with Celluloid from my work on Sidekiq, I knew Celluloid had all the pieces to puzzle to make this easier. In fact, one of the earliest incarnations of Sucker Punch wasn&rsquo;t a gem at all, just some Ruby classes implementing the pieces of Celluloid necessary to put together a background processing queue.</p>

<!--more-->


<p>The resulting code was less than ideal. It worked, but didn&rsquo;t feel like an API that anyone would want to use. From a beginner&rsquo;s perspective, this would stop adoption in its tracks. This is a common challenge with any code we encounter. No doubt, the Ruby standard library has all the tools necessary to make just about anything we can dream of, but sometimes the result isn&rsquo;t ideal. It&rsquo;s the same reason libraries like Rspec and HTTParty can exist. Developers prefer to use simplistic <a href="https://en.wikipedia.org/wiki/Domain-specific_language">DSLs</a> over convoluted, similarly-functioning code. Ruby has always been a language where developers consistently tout their ability to write code that reads well, feeding the levels of developer happiness.</p>

<h2>Why Rewrite Sucker Punch</h2>

<p>It started when <a href="https://github.com/brandonhilkert/sucker_punch/issues/122">a version of Celluloid was yanked from RubyGems.org</a>. This resulted in a flurry of tweets and GH issues detailing their inability to bundle their applications.</p>

<p>As of version <code>0.17</code>, methods in public API changed without supporting documentation. On top of that, the core <code>celluloid</code> gem was split in to a series of child gems causing navigation to be painful.</p>

<p>This made my life as the Sucker Punch maintainer difficult. There were some requests to upgrade Sucker Punch to use Celluloid <code>~&gt; 0.17</code> and I feared of what would happen if I did. This caused me to think about what the future of Sucker Punch looked like without Celluloid. I still use Sucker Punch and believe it&rsquo;s a valuable asset to the community. My goal was to find a way to move it forward productively without experiencing similar pains.</p>

<p>In the end, thanks to some <a href="https://github.com/brandonhilkert/sucker_punch/pull/126">communinity contributions</a>, <a href="https://github.com/brandonhilkert/sucker_punch/blob/master/CHANGES.md#160">Sucker Punch <code>1.6.0</code> was released with Celluloid <code>0.17.2</code> support</a>.</p>

<h2>Where to now?</h2>

<p>Around that same time, Mike Perham had been writing about his experiences <a href="http://www.mikeperham.com/2015/10/14/optimizing-sidekiq/">optimizing Sidekiq</a> and <a href="http://www.mikeperham.com/2015/10/14/should-you-use-celluloid/">whether continuing with Celluloid made sense for Sidekiq</a>. Having less experience with multi-threading, it didn&rsquo;t make sense for me to reinvent the wheel.</p>

<p>I had been hearing about <a href="https://github.com/ruby-concurrency/concurrent-ruby"><code>concurrent-ruby</code></a> through a variety of outlets, one of which was Rails <a href="https://github.com/rails/rails/pull/20866">replacing the existing concurrency latch with similar functionality from <code>concurrent-ruby</code></a>. After poking around <code>concurrent-ruby</code>, I realized it had all the tools necessary to build a background job processing library. Much like Celluloid in that respect, had the tools, but lacked the simple DSL for the use case.</p>

<p>What if Sucker Punch used <code>concurrent-ruby</code> in place of <code>celluloid</code>?</p>

<p>I can hear what you&rsquo;re thinking&hellip;&ldquo;What&rsquo;s the difference? You&rsquo;re swapping one dependency for another!&rdquo;. 100% true. The difference was that the little bit of communication I had with the maintainers of <code>concurrent-ruby</code> felt comfortable, easy, and welcoming. And with <code>concurrent-ruby</code> now a dependency of Rails, it&rsquo;s even more accessible for those using Sucker Punch within a Rails application (a common use case). But like before, there&rsquo;s no way to be sure that  <code>concurrent-ruby</code> won&rsquo;t cause similar pains/frustrations.</p>

<h2>Celluloid Basics</h2>

<p>A basic Sucker Punch job looks like:</p>

<p>```
class LogJob
  include SuckerPunch::Job</p>

<p>  def perform(event)</p>

<pre><code>Log.new(event).track
</code></pre>

<p>  end
end
```</p>

<p>To run the job asynchronously, we use the following syntax:</p>

<p><code>
LogJob.new.async.perform("new_user")
</code></p>

<p>The most interesting part of this method chain is the <code>async</code>. Removing <code>async</code>, leaves us with a call to a regular instance method.</p>

<p>It so happens that <a href="https://github.com/celluloid/celluloid/wiki/Basic-usage"><code>async</code> is a method in Celluloid that causes the next method to execute asynchronously</a>. And this works because by including <code>SuckerPunch::Job</code>, we&rsquo;re including <code>Celluloid</code>, which gives us the <code>async</code> method on instances of the job class.</p>

<h2>Developing APIs</h2>

<p>If you&rsquo;re familiar with the basics of Celluloid, you&rsquo;ll notice there&rsquo;s not much to Sucker Punch. It adds the Celluloid functionality to job classes and does some things under the hood to ensure there&rsquo;s one queue for each job class.</p>

<p><strong>Early in my <code>concurrent-ruby</code> spike, I realized what a mistake to tie Sucker Punch&rsquo;s API to the API of Celluloid</strong>. Tinkering with the idea of removing Celluloid has left Sucker Punch with two options:</p>

<ol>
<li>Continue using the <code>async</code> method with the new dependency</li>
<li>Break the existing DSL and create a dependency-independent syntax and try my best to document and support the change through the backwards-incompatible change</li>
</ol>


<p>Option 1 is the easy way out. Option 2 is more work, far more scary, but the right thing to do.</p>

<p>I decided to abandon my thoughts about previous versions and write as if it were new today. This will be the basis for the next major release of Sucker Punch (<code>2.0.0</code>).</p>

<p>Settling on abandoning the existing API, the next question is, <strong>&ldquo;What should the new API look like?&rdquo;</strong>.</p>

<p>Being a fan of Sidekiq, it didn&rsquo;t take long for me to realize it could actually make developers lives easier if Sucker Punch&rsquo;s API was the same.</p>

<p>Switching between Sidekiq and Sucker Punch is not uncommon. I look at Sidekiq as Sucker Punch&rsquo;s big brother and often suggest people use it instead when the use case makes sense.</p>

<p>If you&rsquo;re familiar with Sidekiq, using the <code>perform_async</code> class method should look familiar:</p>

<p><code>
LogJob.peform_async("new_user")
</code></p>

<p><strong>So why not use the same for Sucker Punch?</strong></p>

<p>If so, switching between Sidekiq and Sucker Punch would be no more than swapping <code>include Sidekiq::Worker</code> for <code>include SuckerPunch::Job</code> in the job class, aside from the gem installation itself. The result would be less context switching and more opportunity focus on the important parts of the application.</p>

<p>I can hear the same question again, &ldquo;What&rsquo;s the difference? You suggested isolating yourself from a dependency&rsquo;s API and now you&rsquo;re suggesting using another!&rdquo;. I look at this one a little differently&hellip;</p>

<p>Sidekiq is uniquely positioned in the community as a paid open source project. We&rsquo;re happy users of Sidekiq Pro and continue to do so for the support. You can certainly get support for the open source version, but one way to ensure Sidekiq is actively maintained is by paying for it. This financial support from us and others decreases the likelihood Mike will choose to abandon it. Mike&rsquo;s also been public about his long-term interest in maintaining Sidekiq. With all this in mind, I&rsquo;m willing to bank on its existence as the defacto way to enqueue jobs for background processing.</p>

<p>And if for some reason Sidekiq does disappear, there&rsquo;s nothing lost on Sucker Punch. There&rsquo;s no dependency. Just a similar syntax.</p>

<p>Sucker Punch <code>2.0.0</code> will have 2 class methods to enqueue jobs:</p>

<p><code>
LogJob.perform_async("new_user")
</code></p>

<p>and</p>

<p><code>
LogJob.perform_in(5.minutes, "new_user")
</code></p>

<p>The latter defining a delayed processing of the <code>perform</code> method 5 minutes from now.</p>

<h2>Summary</h2>

<p>Settling on a library&rsquo;s API isn&rsquo;t easy. Isolating it from underlying dependencies is the best bet for long-term stability. Using the <a href="https://en.wikipedia.org/wiki/Adapter">adapter pattern</a> can help create a layer (adapter) between your code and the dependency&rsquo;s API. But like always, there are always exceptions.</p>

<p>I&rsquo;m taking a leap of faith that doing what I believe is right won&rsquo;t leave existing users frustrated, ultimately abandoning Sucker Punch altogether.</p>

<p>Sucker Punch <code>v2.0</code> is shaping up to be the best release yet. I&rsquo;m looking forward to sharing it with you.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sidekiq As A Microservice Message Queue]]></title>
    <link href="http://brandonhilkert.com/blog/sidekiq-as-a-microservice-message-queue/"/>
    <updated>2015-11-30T12:06:00-05:00</updated>
    <id>http://brandonhilkert.com/blog/sidekiq-as-a-microservice-message-queue</id>
    <content type="html"><![CDATA[<p>In the recent series on transitioning to microservices, I detailed a path to move a large legacy Rails monolith to a cluster of a dozen microservices. But not everyone starts out with a legacy monolith. In fact, given Rails popularity amongst startups, <strong>it&rsquo;s likely most Rails applications don&rsquo;t live to see 4+ years in production</strong>. So what if we don&rsquo;t have a huge monolith on our hands? Are microservices still out of the question?</p>

<p>Sadly, the answer is, &ldquo;it depends&rdquo;. The &ldquo;depends&rdquo; part is specific to your context. While microservices may seem like the right move for you and your application, it&rsquo;s also possible it could cause a mess if not done carefully.</p>

<!--more-->


<p>This post will explore opportunities for splitting out unique microservices using <a href="http://sidekiq.org/">Sidekiq</a>, without introducing an enterprise message broker like <a href="https://www.rabbitmq.com/">RabbitMQ</a> or <a href="http://kafka.apache.org/">Apache Kafka</a>.</p>

<h2>When are Microservices right?</h2>

<p>Martin Fowler <a href="http://martinfowler.com/articles/microservice-trade-offs.html">wrote about trade-offs that come when introducing microservices</a>.</p>

<p>The article outlines 6 pros and cons introduced when you moved a microservices-based architecture. The strongest argument for microservices is the strengthening of module boundaries.</p>

<p>Module boundaries are naturally strengthened when we&rsquo;re forced to move code to another codebase. The result being, in most cases a group of microservices appears to be better constructed than the legacy monolith it was extracted from.</p>

<p>There&rsquo;s no doubt Rails allows developers to get something up and running very quickly. Sadly, you can do so while making a big mess at the same time. It&rsquo;s worth noting there&rsquo;s nothing stopping a monolith from being well constructed. With some discipline, <a href="https://www.youtube.com/watch?v=KJVTM7mE1Cc">your monolith can be the bright and shiny beauty that DHH wants it to be</a>.</p>

<h2>Sidekiq Queues</h2>

<p>Ok, ok. You get it. Microservices can be awesome, but they can also make a big mess. I want to tell you about how I recently avoided a big mess without going &ldquo;all in&rdquo;.</p>

<p>There&rsquo;s no hiding I&rsquo;m a huge <a href="http://sidekiq.org/">Sidekiq</a> fan. It&rsquo;s my goto solution for background processing.</p>

<p>Sidekiq has the notion of <a href="https://github.com/mperham/sidekiq/wiki/Advanced-Options#workers">named queues</a> for both <a href="https://github.com/mperham/sidekiq/wiki/Advanced-Options#workers">jobs</a> and <a href="https://github.com/mperham/sidekiq/wiki/Advanced-Options#queues">workers</a>. This is great from the standpoint that it allows you to put that unimportant long-running job in a different queue without delayed other important fast-running jobs.</p>

<p>A typical worker might look like:</p>

<p>```
class ImportantWorker
  include Sidekiq::Worker</p>

<p>  def perform(id)</p>

<pre><code># Do the important stuff
</code></pre>

<p>  end
end
```</p>

<p>If we want to send this job to a different queue, we&rsquo;d add <code>sidekiq_options queue: :important</code> to the worker, resulting in:</p>

<p>```
class ImportantWorker
  include Sidekiq::Worker
  sidekiq_options queue: :important</p>

<p>  def perform(id)</p>

<pre><code># Do the important stuff
</code></pre>

<p>  end
end
```</p>

<p>Now, we need to make sure the worker process that&rsquo;s running the jobs knows to process jobs off this queue. A typical worker might be invoked with:</p>

<p><code>
bin/sidekiq
</code></p>

<p>Since new jobs going through this worker will end up on the <code>important</code> queue, we want to make sure the worker is processing jobs from the <code>important</code> queue too:</p>

<p><code>
bin/sidekiq -q important -q default
</code></p>

<p><em>Note: Jobs that don&rsquo;t specify a queue will go to the <code>default</code> queue. We have to include the <code>default</code> queue when we using the <code>-q</code> option, otherwise the default queue will be ignored in favor of the queue passed to the <code>-q</code> option.</em></p>

<p>The best part, you don&rsquo;t even have to have multiple worker processes to process jobs from multiple queues. Furthermore, the <code>important</code> queue can be checked twice as often as the <code>default</code> queue:</p>

<p><code>
bin/sidekiq -q important,2 -q default
</code></p>

<p>This flexibility of where jobs are enqueued and how they&rsquo;re processed gives us an incredible amount of freedom when building our applications.</p>

<h2>Extracting Worker to a Microservice</h2>

<p>Let&rsquo;s assume that we&rsquo;ve deployed your main application to Heroku. The application uses Sidekiq and we&rsquo;ve included a Redis add-on. With the addition of the add-on, our application now has a <code>REDIS_URL</code> environment variable that Sidekiq connects to on startup. We have a web process, and worker process. A pretty standard Rails stack:</p>

<p><img class="center" src="/images/sidekiq/rails-web-worker.png" title="&ldquo;Rails with typical worker process&rdquo;" ></p>

<p><strong>What&rsquo;s stopping us from using that same <code>REDIS_URL</code> in another application?</strong></p>

<p>Nothing, actually. And if we consider what we know about the isolation of jobs in queue and workers working on specific queues, there&rsquo;s nothing stopping us from having workers for a specific queue in a different application altogether.</p>

<p>Remember <code>ImportantWorker</code>, imagine the logic for that job was better left for a different application. We&rsquo;ll leave that part a little hand-wavey because there still should be a really good reason to do so. But we&rsquo;ll assume you&rsquo;ve thought long and hard about this and decided the core application was not a great place for this job logic.</p>

<p>Extracting the worker a separate application might now look something like this:</p>

<p><img class="center" src="/images/sidekiq/rails-with-microservice.png" title="&ldquo;Using Sidekiq as a Message Queue between two Rails microservices&rdquo;" ></p>

<h2>Enqueueing Jobs with the Sidekiq Client</h2>

<p>Typically, to enqueue the <code>ImportantWorker</code> above, we&rsquo;d call the following from our application:</p>

<p><code>
ImportantWorker.perform_async(1)
</code></p>

<p>This works great when <code>ImportantWorker</code> is defined in our application. With the expanded stack above, <code>ImportantWorker</code> now lives in a new microservice, which means we don&rsquo;t have access to the <code>ImportantWorker</code> class from within the application. We <em>could</em> define it in the application just so we can enqueue it, with the intent that the application won&rsquo;t process jobs for that worker, but that feels funny to me.</p>

<p>Rather, we can turn to the underlying Sidekiq client API to enqueue the job instead:</p>

<p>```
Sidekiq::Client.push(
  &ldquo;class&rdquo; => &ldquo;ImportantWorker&rdquo;,
  &ldquo;queue&rdquo; => &ldquo;important&rdquo;,
  &ldquo;args&rdquo; => [1]
)</p>

<p>```</p>

<p><em>Note: We have to be sure to define the <code>class</code> as a string <code>"ImportantWorker"</code>, otherwise we&rsquo;ll get an exception during enqueuing because the worker isn&rsquo;t defined in the application.</em></p>

<h2>Processing Sidekiq Jobs from a Microservice</h2>

<p>Now we&rsquo;re pushing jobs to the <code>important</code> queue, but have nothing in our application to process them. In fact, our worker process isn&rsquo;t even looking at that queue:</p>

<p><code>
bin/sidekiq -q default
</code></p>

<p>From our microservice, we setup a worker process to <strong>ONLY</strong> look at the <code>important</code> queue:</p>

<p><code>
bin/sidekiq -q important
</code></p>

<p>We define the <code>ImportantWorker</code> in our microservice:</p>

<p>```
class ImportantWorker
  include Sidekiq::Worker
  sidekiq_options queue: :important</p>

<p>  def perform(id)</p>

<pre><code># Do the important stuff
</code></pre>

<p>  end
end
```</p>

<p>And now when the worker picks jobs out of the <code>important</code> queue, it&rsquo;ll process them using the <code>ImportantWorker</code> defined above in our microservice.</p>

<p>If we wanted to go one step further, the microservice could then enqueue a job using the Sidekiq client API to a queue that only the core application is working on in order to send communication back the other direction.</p>

<h2>Summary</h2>

<p>Any architectural decision has risks. Microservices are no exception. Microservices can be easier than an enterprise message broker, cluster of new servers and a handful of devops headaches.</p>

<p>I originally dubbed this the &ldquo;poor man&rsquo;s message bus&rdquo;. With more thought, there&rsquo;s nothing &ldquo;poor&rdquo; about this. Sidekiq has a been a reliable piece of our infrastructure and I have no reason to believe that&rsquo;ll change, even if we are using it for more than just simple background processing from a single application.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Path to Services - Part 1 - Start Small]]></title>
    <link href="http://brandonhilkert.com/blog/a-path-to-services-part-1-start-small/"/>
    <updated>2015-07-27T11:18:00-04:00</updated>
    <id>http://brandonhilkert.com/blog/a-path-to-services-part-1-start-small</id>
    <content type="html"><![CDATA[<p><em>This article was originally posted on the <a href="http://plumbing.pipelinedeals.com/">PipelineDeals Engineering
Blog</a></em></p>

<p>The PipelineDeals web application recently celebrated its ninth birthday. It&rsquo;s
seen its fair share of developers, all of whom had their own idea of &ldquo;clean
code&rdquo;. As a team, we&rsquo;d been brainstorming ways to wrangle certain areas of the
application. The question we&rsquo;d frequently ask ourselves was <em>&ldquo;How do we clean
up [x] (some neglected feature of the application)?</em>&rdquo;.</p>

<!--more-->


<p>Reasonable solutions ended up being:</p>

<ol>
<li>Rewrite it</li>
<li>Rewrite and put it elsewhere</li>
</ol>


<p>In short, we chose to rewrite many of the hairy areas of the app into separate services communicating over HTTP. It&rsquo;s been about a year since our first commit in a separate service, and we&rsquo;ve learned quite a bit since then. This is part 1 in a series of posts related to our transition to microservices.</p>

<h2>How we got here</h2>

<p>This was us 18 months ago. PipelineDeals was a crufty Rails 2 application that many of us were scared to open. It&rsquo;d been several years of adding feature upon feature without consistent knowledge, style, or guidance. And it&rsquo;s probably not surprising we had what we did. Regardless, we needed to fix it.</p>

<p>One of our goals was to move to Rails 3, and later more updated versions, but in order to get there, we had to refactor (or remove) quite a bit of code to make the transition easier.</p>

<p>This, to me, was a huge factor around our decision to move to a more service-focused approach. <a href="https://www.youtube.com/watch?v=KJVTM7mE1Cc">At this year&rsquo;s Railsconf keynote</a>, DHH joked about the &ldquo;majestic monolith&rdquo; and how many companies prematurely piece out services, all to later suffer pain when they realize it was a premature optimization.</p>

<p>The same could be said for our move. Instead of spinning out separate services, we could have cleaned up the mess we had by refactoring every nasty piece of our app. We could have turned our ugly monolith into a majestic one. But while it would&rsquo;ve been possible, our team agreed we were better served by more or less starting over. Not in the big-bang rewrite sense, but instead to stand up brand new service apps when we added new features, and when it made sense. &ldquo;Made sense&rdquo; is the key here. There have been many times when it didn&rsquo;t make sense over the past 12 months. But we&rsquo;re learning and getting better at identifying the things that are good candidates for a more isolated service.</p>

<h2>Now what?</h2>

<p><em>Do we wait for the next requested feature or what?</em></p>

<p>At one of our weekly team hangouts, we watched a talk focused on starting by isolating the responsibility of Email. It was the perfect introduction and motivation for us to get a small win and some experience under our belts. For some reason prior, we didn&rsquo;t have a great sense of how to start making that transition.</p>

<p>The idea was to take our emails (and there were plenty) and move them to a separate Rails app that&rsquo;s only responsibilty is sending email. While it sounds trivial, the idea alone introduces a lot of interesting questions: <em>What do we do with those really nasty emails that have 30 instance variables? What do we do if the email service is down? How do we trigger an email to be sent?</em></p>

<h2>Rails new</h2>

<p>We created a new Rails 4 app, removed all the stuff we didn&rsquo;t need and created a golden shrine where emails could flourish&hellip;but seriously, that&rsquo;s all it did. And it did it really well.</p>

<p>The next question was how to send emails from the main application. We&rsquo;re very happy <a href="http://sidekiq.org/pro/">Sidekiq Pro</a> users, and one of the benefits we love about Sidekiq is the built-in retries. This gives us a layer of reliability outside of the code layer. So rather than build some ad-hoc retry mechanism by creating a counter in ruby, and rescuing failures within a certain range, we shoot off a job. If it fails because the network is down, or the endpoint isn&rsquo;t available, the job will retry soon after and continue down the happy path. Sidekiq retries are a recurring theme with our infrastructure. We&rsquo;ve made a number of decisions around the fact that we have this advantage already built-in, and we might as well take advantage of it. More on that to come.</p>

<h2>Communicate</h2>

<p>The defacto communication method between services is over HTTP. And we did nothing different. Our services use JSON payloads to exchange data, which let&rsquo;s us easily take advantage of Sidekiq on both ends.</p>

<p>So now, rather than invoking a built-in Rails mailer like:</p>

<p><code>
UserMailer.welcome(current_user).deliver
</code></p>

<p>we invoke a PORO to send off the communication:</p>

<p><code>
Email.to current_user, :user_welcome
</code></p>

<p>where <code>Email</code> is defined as</p>

<p>```
class Email
  def initialize(users, email_key, opts)</p>

<pre><code>@users, @email_key, @opts = users, email_key, opts
</code></pre>

<p>  end</p>

<p>  def self.to(users, email_key, opts = {})</p>

<pre><code>new(users, email_key, opts).queue_email
</code></pre>

<p>  end</p>

<p>  def queue_email</p>

<pre><code>opts[:email_key] = email_key
opts[:to] ||= email_array
opts[:name] ||= first_users_name
opts[:user_id] ||= user_id
opts[:account_id] ||= account_id

json = JSON.generate(opts)
RestClient.post(ENV["PIPELINE_EMAIL_URL"], json, :content_type =&gt; :json)
</code></pre>

<p>  end
end
```</p>

<p>There&rsquo;re a number of use-case specific variables above, but the <code>email_key</code> is probably the most important. We used that to describe what email should be invoked on the service.</p>

<p>In the above example, we triggered the <code>welcome</code> email on the <code>UserMailer</code> class. We translated this request into an email key of <code>user_welcome</code>.</p>

<p>This key then gets interpreted by the Email service app and turned into an actual <code>Mailer</code> class and method within it. We could have done this in a variety of ways, but we split the string on the service-side at the <code>_</code>, and the first element described the mailer, the rest the method. So in this case, it gets interpreted as <code>UserMailer#welcome</code>.</p>

<p>One thing this pattern allowed us to do was almost full copy/paste the old mailer methods in to the new Email service application.</p>

<h2>Failures, failures, failures</h2>

<p>&ldquo;What if the service is down?&rdquo; you say, &ldquo;the email request will fail!&rdquo; Sure will.</p>

<p>So let&rsquo;s wrap that request in a Sidekiq job to take advantage of the built-in retries.</p>

<p>Rather than invoke the following method in the email object:</p>

<p><code>
RestClient.post(ENV["PIPELINE_EMAIL_URL"], json, :content_type =&gt; :json)
</code></p>

<p>we&rsquo;ll shoot off a Sidekiq job instead, changing the <code>queue_email</code> method to:</p>

<p>```
def queue_email
  opts[:email_key] = email_key
  opts[:to] ||= email_array
  opts[:name] ||= first_users_name
  opts[:user_id] ||= user_id
  opts[:account_id] ||= account_id</p>

<p>  EmailWorker.perform_async(opts)
end
```</p>

<p>There we have it. Network-proof email requests!</p>

<p>Not so fast&hellip;</p>

<p>Astute readers will probably recognize that the service-side network communication can potentially also fail. This is becoming a pattern, huh? More communication, more potential for failure and more potential headaches.</p>

<p>On the <strong>service side</strong>, we have a controller that takes in the request for the email and immediately serializes it to a Sidekiq job:</p>

<p>```
  def create</p>

<pre><code>EmailWorker.perform_async(parsed_params)
head :accepted
</code></pre>

<p>  end</p>

<p>  private</p>

<p>  def parse_params</p>

<pre><code>JSON.parse(request.body) || {}
</code></pre>

<p>  end
end
```</p>

<p>Because we immediately serialize the job to Sidekiq, we&rsquo;ve successfully acknowledged the job was received, and the main app&rsquo;s Sidekiq job completes successfully. Now the email service can move on to doing the heavy-lifting in whatever way makes the most sense. In our case, we use Mailgun to send our emails, so the <code>EmailWorker</code> Sidekiq job invokes a new mailer based on the <code>email_key</code> param and sends it off to mailgun for transport. And because it&rsquo;s wrapped in a Sidekiq job, we can sleep well knowing that the Mailgun request can fail and the job will successfully retry until it goes through.</p>

<h2>Summary</h2>

<p>Service communication is definitely not for the faint of heart and as a team, we can completely appreciate the challenges that come along with keeping services in sync now&mdash;especially having stood up about 8 new services in the last 12 months.</p>

<p>Sidekiq has been the queueing solution we&rsquo;ve leaned on to keep communication in sync and reliable. We&rsquo;ve also written a few internal tools that piggy-backy off Sidekiq that we&rsquo;re really excited share with the community in the near future.</p>

<p>Part II, in this series, will discuss the methods of communication necessary to consider when implementing a service-based architecture.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Absolutes as an AntiPattern]]></title>
    <link href="http://brandonhilkert.com/blog/absolutes-as-an-antipattern/"/>
    <updated>2014-09-28T22:35:00-04:00</updated>
    <id>http://brandonhilkert.com/blog/absolutes-as-an-antipattern</id>
    <content type="html"><![CDATA[<p>It’s been awhile since my last post — almost 2 months to be specific. A trip to Portugal, getting sick and a minor run-in with a table saw made it challenging to post anything for the last couple weeks. But I’d be lying if I said I was itching to write.</p>

<p>During that time, I didn’t have anything screaming to be talked about. I have a long list of “decent post” topics, but none of them got me particularly excited. Until today…</p>

<!--more-->


<p>I stumbled on a blog post related to Rails’s upcoming <a href="http://edgeguides.rubyonrails.org/active_job_basics.html">Active Job feature</a>. While demonstrating the syntax for specifying the adapter, there was comment in the code snippet that said <em>“inline and other worse options”</em>. This caught me by surprise and bummed me out at the same time. Not only because I’m the author of <a href="https://github.com/brandonhilkert/sucker_punch">one of them</a>, but because there are a handful of background processing libraries in Ruby that are really good.</p>

<p>So, naturally, I pinged the author and mentioned the comment might be sending the wrong message. He responded with “I consider sidekiq to be the best background processing tool available for Ruby.” And then later, <em>“sidekiq is significantly better that delayed_job and resque. You’re welcome to disagree”</em>.</p>

<p><em>Note: The responses above illustrate a general sentiment. By no means is this post focused on the individual that said them.</em></p>

<p>The thing is, I don’t completely disagree. As you probably already know, I’m a huge fan of of <a href="http://sidekiq.org/">Sidekiq</a>. I’ve contributed to the project and believe Sidekiq’s author, <a href="https://www.mikeperham.com/">Mike Perham</a> is not only a great leader in the Ruby community, but a great example of how to manage and lead open source projects well.</p>

<p>However, those responses reminded me how damaging absolutes can be. You’ve probably heard it before:</p>

<blockquote><p>“we can <strong>ABSOLUTELY NOT</strong> do x, y and z”</p></blockquote>

<p><em>Why not? Will the world end? How do I know?</em></p>

<p>or, what about:</p>

<blockquote><p>“this feature needs to go out tomorrow, no excuses”</p></blockquote>

<p><em>What if there is an excuse? What if it’s not ready? Will I be fired? Will our company go under?</em></p>

<p>There are trade-offs to every decision made. While some options may not be ideal, they may still work, perhaps just not as well.</p>

<p>Absolutes beg the toddler question, <em>”why?”</em>. <em>Why won’t that language X work?</em> <em>Why can’t we use Y?</em>. If you don’t know the answer to those questions, you’re doing yourself a disservice by not asking. Maybe the person has thoroughly researched the topic to come up with those conclusions. But, maybe, they haven’t.</p>

<p>I’ve noticed those who do exhaustive research on a topic tend to present the information in a different manner. They’re confident the facts they found will prove their case and seem to present their findings less defensively. No, <em>”it has to be done like this”</em>. More like, <em>“I found a few ways to fix the problem and here’s why I think option 1 might be the best solution. What do you think?”</em>.</p>

<p>Whether you follow agile or any other methodology, predictions and absolutes have no place in conversations. There are plenty of examples of failed software projects. I’m pretty sure all of them featured people promising the work would be done in time and under budget. Buuuuuuut, it wasn’t.</p>

<h2>Background Jobs for the Big Boys</h2>

<p>Delayed Job was the first Ruby background processing library I used. I remember feeling badass that I was doing all this complicated stuff in the background. But at some point, there we so many jobs and so much activity that pushing and pulling jobs out of the primary data store wasn’t efficient. Reads from the web UI would slow down (and ultimately stop) and users would bail. Unfortunately, I couldn’t pop up a message and say, <em>”hey, hope you don’t mind, but I’m doing some pretty crucial shit in the background here, so you’re experience is gonna be sucky for a bit! sorry :(”</em>.</p>

<p>So, at the time, Resque was the next logical transition. I migrated the previously written jobs from Delayed Job to Resque and experienced a new level of <em>bad ass</em>. Fast forward 4 years — I still work on projects using Resque. Needless to say, it’s a pretty awesome piece of open source software.</p>

<p>A few years ago, Sidekiq came along. While I didn’t know much about multi-threading code in Ruby, I tried it on a side project and was floored at the results. Those 6 Heroku workers that I’d been paying for could be compacted in to 1?!?! And on top of that, I only needed 1 worker that had 25 workers working against the queue?!?!</p>

<p>But then one day, I dropped it in to a project that was using MongoDB and MongoMapper as ORM and things didn’t go so well. In the end, MongoMapper wasn’t thread-safe, which is a requirement of Sidekiq worker code. So in that case, was Sidekiq the best tool for the job? While I would’ve loved to use Sidekiq on that project, it certainly (like the absolute there…) wasn’t the right tool for <em>that</em> job.</p>

<p>And what about when I first started with Delayed Job…we were a small startup with limited cash. While it seems silly to balk over an extra $35 Heorku dyno, it was $35 that could’ve gone towards something else. Not to mention the extra Redis instance, along with the expertise to make sure the thing didn’t fall over and die. Was Sidekiq (or Resque for that matter) the best tool for that job? Nope!</p>

<p>Fast forward a few years, I had the need for an in-process background processing library, so <a href="http://brandonhilkert.com/blog/why-i-wrote-the-sucker-punch-gem/">I wrote one</a>. That need was driven off the motivation above — needing to minimize cost and complexity. Would Sidekiq have worked for that project? Of course! In fact, it was using Sidekiq for a year or so before I transitioned the jobs to use Sucker Punch.</p>

<h2>Use Cases</h2>

<p>At this point, you should be noticing a trend, right? The examples above were unique use cases with a unique set of requirements and limitations. Sure, if every project I worked on had unlimited resources (both time and money), Sidekiq would be probably be my go-to the majority of time (even when writing that sentence I hesitated and almost wrote “all the time”).</p>

<p>But I hesitate now. Because I remember learning about the new cool things and thinking, <em>”This is the best! There’s no way I’ll never not use it”</em>. And when I would talk to other developers, I would rave about how <em>X</em> is the best for <em>Y</em>. And now I realize I was a dummy for doing that. There’s no way I could’ve made that judgement for someone else and their work. What I really should’ve said was, <em>”I tried [insert fancy new gem/technique] for the first time the other day. It worked really well for doing X in my project that does Y”</em>. That definitely doesn’t sound as exciting, but it was the truth.</p>

<p>I feel fortunate to get to write Ruby everyday. It’s incredibly expressive, which is why the debate over the countless ways to do something is great. Does the code express the right intent? For your method, it might. But for mine, it might express the complete opposite. The good news is, that’s OK. Both versions will work and the fact that we can have conversations like that is a praise for the language itself. I prefer to have the opportunity to have that conversation about style, rather than a language more black and white. Maybe it’s the creative in me, but it seems like no 2 Ruby solutions will be identical and that’s one of the things I love most about writing Ruby.</p>

<p>We often joke about the stack overflow post that starts with <em>“I’m thinking about learning Rails…is it better than PHP?”</em>. Or even more relevant today, <em>”Which javascript framework should I use?”</em>.</p>

<p>And then there’s the guy who comes along and is all like, <em>”Let’s back up, what are you doing and why do you absolutely need a FRAMEWORK????”</em>. While I used to ignore those types of comments, they’re the kind that I think about now and find myself typing. And that has me wondering…why the change?</p>

<h2>Experience, Experience, Experience</h2>

<p>I got to thinking about how I felt when I was first learning to program. When I started to feel comfortable with Rails, my confidence was through the roof. But at the same time, my naivety was at an all time high. I had had minimal experiences with software systems that were either critical or heavily-loaded. But having found Resque, I felt like I could solve the world’s problems. This is somewhat of an exaggeration, but not too far off. I realized that, as it relates to my technical career, my naivety is doing this related to time:</p>

<p><img class="center" src="/images/absolutes/naivety-graph.png" title="&ldquo;Graph of Naivety over Time&rdquo;" ></p>

<p>The less naivety, the more options and, naturally, certainty takes a nose dive:</p>

<p><img class="center" src="/images/absolutes/certainty-graph.png" title="&ldquo;Graph of Certainty over Time&rdquo;" ></p>

<p>The more I learn about programming in general, the more questions I have. Fortunately, experiences have brought me to a point where I can fairly weigh the use of Sucker Punch or Delayed Job for a particular use case. I’m not sure projecting absolutes from up high does anyone any good. Beginners will take it as the word and spread the message to others they come across.</p>

<p>Use cases are real. And the less we force our own biases on people, the faster they’ll realize experience is key and the random guy behind the cat avatar on Stack Overflow might actually be asking the right questions — even if they are convoluted.</p>

<p>Next time you hear an absolute, ask <em>”Why?”</em>.</p>
]]></content>
  </entry>
  
</feed>
